{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/skshmjn/bert-ner?scriptVersionId=214325775\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install transformers datasets tokenizers seqeval evaluate peft -q ","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2024-12-22T15:50:33.874845Z","iopub.execute_input":"2024-12-22T15:50:33.875205Z","iopub.status.idle":"2024-12-22T15:50:48.81171Z","shell.execute_reply.started":"2024-12-22T15:50:33.875173Z","shell.execute_reply":"2024-12-22T15:50:48.810606Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import datasets \nimport numpy as np \nimport torch \nimport json\nfrom transformers import pipeline\nfrom evaluate import load\nfrom transformers import BertTokenizerFast\nfrom transformers import DataCollatorForTokenClassification , DataCollatorWithPadding\nfrom transformers import AutoModelForTokenClassification , AutoTokenizer\nfrom transformers import TrainingArguments, Trainer \nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:50:48.813818Z","iopub.execute_input":"2024-12-22T15:50:48.814146Z","iopub.status.idle":"2024-12-22T15:50:50.375718Z","shell.execute_reply.started":"2024-12-22T15:50:48.814104Z","shell.execute_reply":"2024-12-22T15:50:50.374873Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"conll2003 = datasets.load_dataset(\"conll2003\", trust_remote_code=True)\nconll2003","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:50:50.376695Z","iopub.execute_input":"2024-12-22T15:50:50.37694Z","iopub.status.idle":"2024-12-22T15:50:56.113467Z","shell.execute_reply.started":"2024-12-22T15:50:50.376916Z","shell.execute_reply":"2024-12-22T15:50:56.11273Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e73494f8a53422c95dbeb11ed43769d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee7e44b4cb9a436a8b3611fdfa80d9f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e427490b784fbd81151e6be8d744b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778b168a0bbc44c38c08561d42797636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffbbe86e52b04926a30df8f1d24eb0ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b1544c0e7c145d484e1c2b73d79a1d0"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"conll2003[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:28:48.795882Z","iopub.execute_input":"2024-12-19T19:28:48.796189Z","iopub.status.idle":"2024-12-19T19:28:48.803938Z","shell.execute_reply.started":"2024-12-19T19:28:48.796162Z","shell.execute_reply":"2024-12-19T19:28:48.803068Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ner_classes = conll2003[\"train\"].features[\"ner_tags\"].feature.names\nner_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:52:25.973536Z","iopub.execute_input":"2024-12-22T15:52:25.973905Z","iopub.status.idle":"2024-12-22T15:52:25.98009Z","shell.execute_reply.started":"2024-12-22T15:52:25.973873Z","shell.execute_reply":"2024-12-22T15:52:25.979225Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"example = conll2003[\"train\"][345]\nexample['tokens'] ,[ner_classes[i] for i in example['ner_tags']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T19:28:48.817008Z","iopub.execute_input":"2024-12-19T19:28:48.817378Z","iopub.status.idle":"2024-12-19T19:28:48.825559Z","shell.execute_reply.started":"2024-12-19T19:28:48.817332Z","shell.execute_reply":"2024-12-19T19:28:48.824517Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(['SOCCER', '-', 'GLORIA', 'BISTRITA', 'BEAT', '2-1', 'F.C.', 'VALLETTA', '.'],\n ['O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'O'])"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\ndef tokenize_and_align_labels(examples, label_all_tokens=True): \n\n    # Tokenisation\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n    labels = [] \n\n    # checking all the labels and adding label for word piece \n    for i, label in enumerate(examples[\"ner_tags\"]):\n        \n        word_ids = tokenized_inputs.word_ids(batch_index=i) \n        previous_word_idx = None \n        label_ids = []\n        \n        for word_idx in word_ids: \n            if word_idx is None: \n               \n                label_ids.append(0)\n           \n            elif word_idx != previous_word_idx:\n               \n                label_ids.append(label[word_idx]) \n            else: \n               \n                label_ids.append(label[word_idx] if label_all_tokens else 0) \n                 \n            previous_word_idx = word_idx \n        labels.append(label_ids) \n    tokenized_inputs[\"labels\"] = labels \n    return tokenized_inputs ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:50:56.115878Z","iopub.execute_input":"2024-12-22T15:50:56.116514Z","iopub.status.idle":"2024-12-22T15:50:56.847447Z","shell.execute_reply.started":"2024-12-22T15:50:56.116486Z","shell.execute_reply":"2024-12-22T15:50:56.846443Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11cd790a18b34a41966dd7dbb784b8a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33e3ecb3de148d789d1264d1ba06d2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21aac30b5913436bb73fb04b462a15d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d28c1c4af7e4457aedcf95ff7ba43e5"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"result = tokenize_and_align_labels(conll2003['train'][345:346])\nprint(result)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(result[\"input_ids\"][0]),result[\"labels\"][0]): \n    print(f\"{token:_<40} {label}\") ","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns([\"tokens\",\"pos_tags\", \"chunk_tags\", \"ner_tags\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:50:56.848538Z","iopub.execute_input":"2024-12-22T15:50:56.848811Z","iopub.status.idle":"2024-12-22T15:50:58.857471Z","shell.execute_reply.started":"2024-12-22T15:50:56.848785Z","shell.execute_reply":"2024-12-22T15:50:58.856779Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fd84091f14f4e0e95affbdc5c83f379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a228c088b4d44c31b94656ee0a7c3e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ace7782232a49b3b1fdd298ffd98151"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenized_datasets['train'][0:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:35:20.045449Z","iopub.execute_input":"2024-12-20T07:35:20.0457Z","iopub.status.idle":"2024-12-20T07:35:20.07999Z","shell.execute_reply.started":"2024-12-20T07:35:20.045674Z","shell.execute_reply":"2024-12-20T07:35:20.079241Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'id': ['0', '1', '2'],\n 'input_ids': [[101,\n   7327,\n   19164,\n   2446,\n   2655,\n   2000,\n   17757,\n   2329,\n   12559,\n   1012,\n   102],\n  [101, 2848, 13934, 102],\n  [101, 9371, 2727, 1011, 5511, 1011, 2570, 102]],\n 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n  [1, 1, 1, 1],\n  [1, 1, 1, 1, 1, 1, 1, 1]],\n 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100],\n  [-100, 1, 2, -100],\n  [-100, 5, 0, 0, 0, 0, 0, -100]]}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer) \nmetric = load(\"seqeval\") \ndef compute_metrics(eval_preds): \n \n    pred_logits, labels = eval_preds \n    \n    pred_logits = np.argmax(pred_logits, axis=2) \n    \n    predictions = [ \n        [ner_classes[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n        for prediction, label in zip(pred_logits, labels) \n    ] \n    \n    true_labels = [ \n      [ner_classes[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n       for prediction, label in zip(pred_logits, labels) \n   ] \n    results = metric.compute(predictions=predictions, references=true_labels) \n    return { \n   \"precision\": results[\"overall_precision\"], \n   \"recall\": results[\"overall_recall\"], \n   \"f1\": results[\"overall_f1\"], \n  \"accuracy\": results[\"overall_accuracy\"], \n  } ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:50:58.858558Z","iopub.execute_input":"2024-12-22T15:50:58.858832Z","iopub.status.idle":"2024-12-22T15:50:59.250718Z","shell.execute_reply.started":"2024-12-22T15:50:58.858804Z","shell.execute_reply":"2024-12-22T15:50:59.249874Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee7fa6ff916406b8396d0a7a61b54f9"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"args = TrainingArguments( \n\"test-ner\",\nevaluation_strategy = \"epoch\", \nlearning_rate=2e-5, \nper_device_train_batch_size=64, \nper_device_eval_batch_size=64, \nnum_train_epochs=5, \nweight_decay=0.01, \n) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:40:25.573631Z","iopub.execute_input":"2024-12-22T15:40:25.574073Z","iopub.status.idle":"2024-12-22T15:40:25.589343Z","shell.execute_reply.started":"2024-12-22T15:40:25.574031Z","shell.execute_reply":"2024-12-22T15:40:25.587684Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:40:37.570738Z","iopub.execute_input":"2024-12-22T15:40:37.571155Z","iopub.status.idle":"2024-12-22T15:40:40.449777Z","shell.execute_reply.started":"2024-12-22T15:40:37.571118Z","shell.execute_reply":"2024-12-22T15:40:40.44835Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"355f53847ca9490fa15e98b6c4704043"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"trainer = Trainer( \n    model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-12-22T15:40:42.956809Z","iopub.execute_input":"2024-12-22T15:40:42.957264Z","iopub.status.idle":"2024-12-22T15:40:42.976561Z","shell.execute_reply.started":"2024-12-22T15:40:42.957189Z","shell.execute_reply":"2024-12-22T15:40:42.975295Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_24/999771.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:14:14.860215Z","iopub.execute_input":"2024-12-18T12:14:14.860964Z","iopub.status.idle":"2024-12-18T12:14:24.245182Z","shell.execute_reply.started":"2024-12-18T12:14:14.860932Z","shell.execute_reply":"2024-12-18T12:14:24.244032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"ner_model\")\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:15:19.574321Z","iopub.execute_input":"2024-12-18T12:15:19.57469Z","iopub.status.idle":"2024-12-18T12:15:20.493965Z","shell.execute_reply.started":"2024-12-18T12:15:19.574659Z","shell.execute_reply":"2024-12-18T12:15:20.493069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(ner_classes)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(ner_classes)\n}\n\nconfig = json.load(open(\"ner_model/config.json\"))\nconfig[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id\njson.dump(config, open(\"ner_model/config.json\",\"w\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:15:24.297501Z","iopub.execute_input":"2024-12-18T12:15:24.29825Z","iopub.status.idle":"2024-12-18T12:15:24.304107Z","shell.execute_reply.started":"2024-12-18T12:15:24.298211Z","shell.execute_reply":"2024-12-18T12:15:24.303184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\").to(device)\nnlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n\nexample = \"Narendra Damodardas Modi[a] (born 17 September 1950)[b] is an Indian politician who has served as Prime Minister of India since 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the member of parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right-wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister outside the Indian National Congress.\"\n\nner_results = nlp(example)\n\nprint(ner_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:15:27.276954Z","iopub.execute_input":"2024-12-18T12:15:27.277598Z","iopub.status.idle":"2024-12-18T12:15:27.520492Z","shell.execute_reply.started":"2024-12-18T12:15:27.277563Z","shell.execute_reply":"2024-12-18T12:15:27.519744Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sudo apt-get install git-lfs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:51:41.556225Z","iopub.execute_input":"2024-12-18T12:51:41.557019Z","iopub.status.idle":"2024-12-18T12:51:45.077062Z","shell.execute_reply.started":"2024-12-18T12:51:41.556986Z","shell.execute_reply":"2024-12-18T12:51:45.076106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:55:26.721418Z","iopub.execute_input":"2024-12-18T12:55:26.722333Z","iopub.status.idle":"2024-12-18T12:55:40.879938Z","shell.execute_reply.started":"2024-12-18T12:55:26.722282Z","shell.execute_reply":"2024-12-18T12:55:40.878953Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quantisation","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade transformers auto-round","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:25:26.912945Z","iopub.execute_input":"2024-12-19T16:25:26.913179Z","iopub.status.idle":"2024-12-19T16:26:05.342474Z","shell.execute_reply.started":"2024-12-19T16:25:26.913155Z","shell.execute_reply":"2024-12-19T16:26:05.341318Z"},"scrolled":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nCollecting transformers\n  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting auto-round\n  Downloading auto_round-0.4.3-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from auto-round) (1.1.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-round) (3.1.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from auto-round) (9.0.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-round) (0.2.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from auto-round) (2.4.0)\nRequirement already satisfied: threadpoolctl in /opt/conda/lib/python3.10/site-packages (from auto-round) (3.5.0)\nCollecting lm-eval<0.5,>=0.4.2 (from auto-round)\n  Downloading lm_eval-0.4.7-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from auto-round) (10.3.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from auto-round) (0.60.0)\nRequirement already satisfied: tbb in /opt/conda/lib/python3.10/site-packages (from auto-round) (2022.0.0)\nCollecting intel-extension-for-pytorch (from auto-round)\n  Downloading intel_extension_for_pytorch-2.5.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (7.4 kB)\nCollecting intel-extension-for-transformers (from auto-round)\n  Downloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (0.4.3)\nCollecting jsonlines (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (2.10.2)\nCollecting peft>=0.2.0 (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (2.13.6)\nCollecting pytablewriter (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\nCollecting rouge-score>=0.0.4 (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacrebleu>=1.5.0 (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (1.2.2)\nCollecting sqlitedict (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tqdm-multiprocess (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (0.23.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (0.3.8)\nCollecting word2number (from lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading word2number-1.1.zip (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: more_itertools in /opt/conda/lib/python3.10/site-packages (from lm-eval<0.5,>=0.4.2->auto-round) (10.3.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->auto-round) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-round) (17.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-round) (2.2.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-round) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-round) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-round) (3.9.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->auto-round) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->auto-round) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->auto-round) (3.1.4)\nCollecting schema (from intel-extension-for-transformers->auto-round)\n  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\nCollecting neural-compressor (from intel-extension-for-transformers->auto-round)\n  Downloading neural_compressor-3.1.1-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->auto-round) (0.43.0)\nRequirement already satisfied: tcmlib==1.* in /opt/conda/lib/python3.10/site-packages (from tbb->auto-round) (1.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-round) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-round) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-round) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-round) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-round) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-round) (4.0.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval<0.5,>=0.4.2->auto-round) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval<0.5,>=0.4.2->auto-round) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm-eval<0.5,>=0.4.2->auto-round) (1.16.0)\nCollecting portalocker (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto-round) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto-round) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval<0.5,>=0.4.2->auto-round) (5.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval<0.5,>=0.4.2->auto-round) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval<0.5,>=0.4.2->auto-round) (1.4.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->auto-round) (2.1.5)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (1.2.14)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (4.10.0.84)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (3.10.0)\nCollecting pycocotools (from neural-compressor->intel-extension-for-transformers->auto-round)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-round) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-round) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-round) (2024.1)\nRequirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval<0.5,>=0.4.2->auto-round) (70.0.0)\nCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\nCollecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\nCollecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\nCollecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->auto-round) (1.3.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.13->neural-compressor->intel-extension-for-transformers->auto-round) (1.16.0)\nCollecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval<0.5,>=0.4.2->auto-round)\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->neural-compressor->intel-extension-for-transformers->auto-round) (0.2.13)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (1.4.5)\nDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading auto_round-0.4.3-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.2/214.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lm_eval-0.4.7-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading intel_extension_for_pytorch-2.5.0-cp310-cp310-manylinux2014_x86_64.whl (97.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl (45.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading neural_compressor-3.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\nDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\nDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\nDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\nDownloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\nDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\nDownloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\nDownloading typepy-1.3.2-py3-none-any.whl (31 kB)\nDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score, sqlitedict, word2number\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=06c2a4830e6fe273c9a5fa21d7aecaa833846bd49da2b12524d681970cbd23a6\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=5a17040fcc2ca552d84892daaad3a782f7754b94279ed94a019872747cd761fe\n  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=1d57e9efb6d895e83e84110ce1213974d55a54feb7576594abeac01c3dfa61e4\n  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\nSuccessfully built rouge-score sqlitedict word2number\nInstalling collected packages: word2number, sqlitedict, schema, tqdm-multiprocess, tcolorpy, portalocker, pathvalidate, jsonlines, chardet, sacrebleu, rouge-score, mbstrdecoder, intel-extension-for-pytorch, typepy, tokenizers, pycocotools, transformers, neural-compressor, peft, intel-extension-for-transformers, DataProperty, tabledata, pytablewriter, lm-eval, auto-round\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.20.3\n    Uninstalling tokenizers-0.20.3:\n      Successfully uninstalled tokenizers-0.20.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.46.3\n    Uninstalling transformers-4.46.3:\n      Successfully uninstalled transformers-4.46.3\nSuccessfully installed DataProperty-1.0.1 auto-round-0.4.3 chardet-5.2.0 intel-extension-for-pytorch-2.5.0 intel-extension-for-transformers-1.4.2 jsonlines-4.0.0 lm-eval-0.4.7 mbstrdecoder-1.1.3 neural-compressor-3.1.1 pathvalidate-3.2.1 peft-0.14.0 portalocker-3.0.0 pycocotools-2.0.8 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.3 schema-0.7.7 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.6 tokenizers-0.21.0 tqdm-multiprocess-0.0.11 transformers-4.47.1 typepy-1.3.2 word2number-1.1\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"skshmjn/test-ner\").to(device)\nauto_round_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"skshmjn/test-ner\").to(device)\ntokenizer = AutoTokenizer.from_pretrained('skshmjn/test-ner')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:43:26.506393Z","iopub.execute_input":"2024-12-19T16:43:26.506693Z","iopub.status.idle":"2024-12-19T16:43:40.609772Z","shell.execute_reply.started":"2024-12-19T16:43:26.506661Z","shell.execute_reply":"2024-12-19T16:43:40.608836Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47277d22610341c0aaa07884a3862f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c171ba7e6bfb4e65aa7c4b3c2c7dc2cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6620f0f4f94222b3af51a1cf87dd13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01903ff275c948778563149fb6e308d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa2ef37619554653a3f0d4c13ec38dee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffa09d1d96574217b2e2c3b74efdd146"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from auto_round import AutoRound\nbits, group_size, sym = 4, 128, True\nautoround = AutoRound(auto_round_fine_tuned, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device=device)\nautoround.quantize()\nauto_round_fine_tuned.save_pretrained(\"auto_round_fine_tuned\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:26:18.052264Z","iopub.execute_input":"2024-12-19T16:26:18.052657Z","iopub.status.idle":"2024-12-19T16:29:21.270328Z","shell.execute_reply.started":"2024-12-19T16:26:18.052625Z","shell.execute_reply":"2024-12-19T16:29:21.269562Z"},"scrolled":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stderr","text":"\u001b[38;20m2024-12-19 16:26:18 INFO autoround.py L230: using torch.float16 for quantization tuning\u001b[0m\n\u001b[38;20m2024-12-19 16:26:18 INFO autoround.py L300: start to cache block inputs\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/373 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e14fc2f79a443a818b6e8436936b78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/921 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1227a15ed034596ba921c346b1e9194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-4746b8785c874cc7.parquet:   0%|          | 0.00/33.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1fbe3c6919c48b4a0b33595f42b05db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd6e66010dd84fb58ce89f6137702f60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe094a742604872b7cdcbed6e9d044d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa6990b7e62b420b9236510495119867"}},"metadata":{}},{"name":"stderr","text":"\u001b[38;20m2024-12-19 16:27:15 INFO autoround.py L305: caching done\u001b[0m\nQuantizing bert.encoder.layer.0:   0%|          | 0/12 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:185.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/transformers/cuda/attention_backward.cu:619.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[38;20m2024-12-19 16:27:26 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.002106 -> iter 198: 0.000874\u001b[0m\nQuantizing bert.encoder.layer.1:   8%|▊         | 1/12 [00:11<02:08, 11.72s/it]\u001b[38;20m2024-12-19 16:27:36 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.004475 -> iter 192: 0.001963\u001b[0m\nQuantizing bert.encoder.layer.2:  17%|█▋        | 2/12 [00:22<01:48, 10.89s/it]\u001b[38;20m2024-12-19 16:27:46 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.005013 -> iter 185: 0.002377\u001b[0m\nQuantizing bert.encoder.layer.3:  25%|██▌       | 3/12 [00:32<01:35, 10.62s/it]\u001b[38;20m2024-12-19 16:27:57 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.005801 -> iter 197: 0.002824\u001b[0m\nQuantizing bert.encoder.layer.4:  33%|███▎      | 4/12 [00:42<01:23, 10.49s/it]\u001b[38;20m2024-12-19 16:28:07 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.006753 -> iter 186: 0.003378\u001b[0m\nQuantizing bert.encoder.layer.5:  42%|████▏     | 5/12 [00:52<01:12, 10.41s/it]\u001b[38;20m2024-12-19 16:28:17 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.007400 -> iter 199: 0.003819\u001b[0m\nQuantizing bert.encoder.layer.6:  50%|█████     | 6/12 [01:03<01:02, 10.40s/it]\u001b[38;20m2024-12-19 16:28:28 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.007782 -> iter 197: 0.004108\u001b[0m\nQuantizing bert.encoder.layer.7:  58%|█████▊    | 7/12 [01:13<00:51, 10.37s/it]\u001b[38;20m2024-12-19 16:28:38 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.007302 -> iter 193: 0.003862\u001b[0m\nQuantizing bert.encoder.layer.8:  67%|██████▋   | 8/12 [01:23<00:41, 10.36s/it]\u001b[38;20m2024-12-19 16:28:49 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.008297 -> iter 196: 0.004273\u001b[0m\nQuantizing bert.encoder.layer.9:  75%|███████▌  | 9/12 [01:34<00:31, 10.43s/it]\u001b[38;20m2024-12-19 16:28:59 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.007598 -> iter 197: 0.003140\u001b[0m\nQuantizing bert.encoder.layer.10:  83%|████████▎ | 10/12 [01:44<00:20, 10.42s/it]\u001b[38;20m2024-12-19 16:29:09 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.009005 -> iter 183: 0.002711\u001b[0m\nQuantizing bert.encoder.layer.11:  92%|█████████▏| 11/12 [01:55<00:10, 10.37s/it]\u001b[38;20m2024-12-19 16:29:20 INFO autoround.py L1139: quantized 6/6 layers in the block, loss iter 0: 0.010630 -> iter 193: 0.001414\u001b[0m\nQuantizing bert.encoder.layer.11: 100%|██████████| 12/12 [02:05<00:00, 10.38s/it]\u001b[38;20m2024-12-19 16:29:21 INFO autoround.py L340: quantization tuning time 182.9905276298523\u001b[0m\n\u001b[38;20m2024-12-19 16:29:21 INFO autoround.py L356: Summary: quantized 72/73 in the model,  ['classifier'] have not been quantized\u001b[0m\nQuantizing bert.encoder.layer.11: 100%|██████████| 12/12 [02:05<00:00, 10.49s/it]\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(BertForTokenClassification(\n   (bert): BertModel(\n     (embeddings): BertEmbeddings(\n       (word_embeddings): Embedding(30522, 768, padding_idx=0)\n       (position_embeddings): Embedding(512, 768)\n       (token_type_embeddings): Embedding(2, 768)\n       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n       (dropout): Dropout(p=0.1, inplace=False)\n     )\n     (encoder): BertEncoder(\n       (layer): ModuleList(\n         (0-11): 12 x BertLayer(\n           (attention): BertAttention(\n             (self): BertSdpaSelfAttention(\n               (query): Linear(in_features=768, out_features=768, bias=True)\n               (key): Linear(in_features=768, out_features=768, bias=True)\n               (value): Linear(in_features=768, out_features=768, bias=True)\n               (dropout): Dropout(p=0.1, inplace=False)\n             )\n             (output): BertSelfOutput(\n               (dense): Linear(in_features=768, out_features=768, bias=True)\n               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n               (dropout): Dropout(p=0.1, inplace=False)\n             )\n           )\n           (intermediate): BertIntermediate(\n             (dense): Linear(in_features=768, out_features=3072, bias=True)\n             (intermediate_act_fn): GELUActivation()\n           )\n           (output): BertOutput(\n             (dense): Linear(in_features=3072, out_features=768, bias=True)\n             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n             (dropout): Dropout(p=0.1, inplace=False)\n           )\n         )\n       )\n     )\n   )\n   (dropout): Dropout(p=0.1, inplace=False)\n   (classifier): Linear(in_features=768, out_features=9, bias=True)\n ),\n {'bert.encoder.layer.0.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.351e-02, 1.121e-02, -1.136e-02, -1.248e-02, -1.294e-02, 1.079e-02],\n           [1.165e-02, -1.343e-02, -1.397e-02, -1.295e-02, -1.605e-02, -1.660e-02],\n           [-1.309e-02, 1.318e-02, -1.000e-02, -1.199e-02, -1.046e-02, -1.595e-02],\n           ...,\n           [-1.611e-02, 2.507e-02, -3.308e-02, -1.511e-02, 1.444e-02, -1.488e-02],\n           [-1.530e-02, 1.608e-02, -1.700e-02, -1.736e-02, -1.515e-02, -1.488e-02],\n           [2.426e-02, -3.687e-02, 1.431e-02, 1.981e-02, -3.519e-02, 2.403e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.0.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-2.158e-02, -1.237e-02, 1.225e-02, -1.160e-02, -1.701e-02, -1.576e-02],\n           [1.543e-02, -1.070e-02, 1.575e-02, 1.260e-02, 1.451e-02, 1.054e-02],\n           [1.831e-02, 1.151e-02, -1.043e-02, 9.682e-03, -9.743e-03, 1.472e-02],\n           ...,\n           [-1.999e-02, 1.947e-02, 1.485e-02, 1.266e-02, 1.807e-02, 1.284e-02],\n           [1.520e-02, 1.485e-02, 1.866e-02, 1.532e-02, 1.945e-02, -1.552e-02],\n           [4.242e-02, -4.282e-02, -1.265e-02, 1.648e-02, -4.688e-02, 3.662e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.0.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-8.957e-03, -1.414e-02, 1.011e-02, 9.811e-03, 1.205e-02, 8.369e-03],\n           [9.216e-03, -7.942e-03, 9.689e-03, 8.461e-03, -1.108e-02, -9.193e-03],\n           [-9.758e-03, 8.537e-03, 1.029e-02, -1.061e-02, 1.037e-02, -8.759e-03],\n           ...,\n           [1.296e-02, 1.055e-02, -1.235e-02, -1.157e-02, -1.010e-02, 8.858e-03],\n           [-1.485e-02, -1.395e-02, -1.175e-02, -1.383e-02, -1.154e-02, -1.229e-02],\n           [-1.055e-02, 1.105e-02, 1.179e-02, 1.233e-02, -1.201e-02, -1.358e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.0.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-7.545e-03, 9.216e-03, 8.949e-03, -9.377e-03, 9.750e-03, -9.888e-03],\n           [9.888e-03, -7.477e-03, 1.288e-02, 8.568e-03, 1.218e-02, -1.060e-02],\n           [8.881e-03, -9.987e-03, 1.260e-02, 9.338e-03, -9.491e-03, -1.245e-02],\n           ...,\n           [1.074e-02, -1.357e-02, 1.119e-02, 9.140e-03, 1.001e-02, 9.979e-03],\n           [9.331e-03, 1.336e-02, 1.030e-02, 9.636e-03, 1.102e-02, -1.031e-02],\n           [-6.531e-03, 9.727e-03, -9.445e-03, -7.660e-03, 9.445e-03, -7.736e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.0.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[9.514e-03, 1.196e-02, 1.095e-02, -1.461e-02, -1.260e-02, -1.392e-02],\n           [-1.646e-02, 1.323e-02, -1.070e-02, -1.485e-02, 1.140e-02, -1.450e-02],\n           [-1.134e-02, 1.426e-02, -1.624e-02, 1.422e-02, -1.250e-02, -9.720e-03],\n           ...,\n           [-1.599e-02, -1.793e-02, 1.279e-02, 1.122e-02, 1.414e-02, 1.035e-02],\n           [-1.057e-02, -1.109e-02, 1.112e-02, -1.148e-02, 1.253e-02, 1.263e-02],\n           [1.492e-02, 1.433e-02, 1.319e-02, 2.036e-02, 1.158e-02, -1.160e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.0.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.212e-02, 9.308e-03, 1.164e-02,  ..., 1.170e-02, -1.121e-02, -1.790e-02],\n           [1.086e-02, 1.287e-02, 1.317e-02,  ..., -1.250e-02, -1.181e-02, 9.781e-03],\n           [1.302e-02, 1.330e-02, -1.078e-02,  ..., -1.018e-02, 9.995e-03, 9.766e-03],\n           ...,\n           [-9.361e-03, 1.030e-02, -1.244e-02,  ..., 1.460e-02, -9.209e-03, 1.151e-02],\n           [1.057e-02, 1.009e-02, 1.430e-02,  ..., 1.263e-02, -1.186e-02, 1.218e-02],\n           [-1.173e-02, -1.203e-02, -1.301e-02,  ..., -9.483e-03, 8.545e-03, 1.128e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.1.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.466e-02, -1.366e-02, -1.438e-02, -1.540e-02, 1.236e-02, -1.498e-02],\n           [-1.302e-02, 1.624e-02, 1.386e-02, 1.758e-02, -1.318e-02, 1.299e-02],\n           [-1.155e-02, -1.660e-02, -1.445e-02, -1.236e-02, -1.311e-02, -1.075e-02],\n           ...,\n           [-1.328e-02, 1.633e-02, 1.274e-02, -1.386e-02, -1.502e-02, 1.187e-02],\n           [-1.350e-02, 1.193e-02, -1.337e-02, 1.380e-02, -1.375e-02, -1.104e-02],\n           [-1.266e-02, -1.355e-02, 1.308e-02, 1.271e-02, -1.682e-02, -1.271e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.1.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.279e-02, 1.125e-02, -1.624e-02, 1.636e-02, -1.142e-02, 1.179e-02],\n           [1.756e-02, -1.591e-02, -1.607e-02, 1.315e-02, 1.205e-02, -1.582e-02],\n           [1.356e-02, -1.219e-02, 1.275e-02, -1.884e-02, -1.286e-02, -1.578e-02],\n           ...,\n           [-1.049e-02, -1.327e-02, 1.564e-02, 1.653e-02, 1.479e-02, 1.229e-02],\n           [-1.566e-02, 1.122e-02, 1.214e-02, -1.003e-02, -1.105e-02, -1.211e-02],\n           [1.677e-02, 1.312e-02, 1.533e-02, 1.225e-02, 1.376e-02, 1.244e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.1.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-8.797e-03, -1.450e-02, -9.514e-03, -8.781e-03, -1.106e-02, 1.016e-02],\n           [9.056e-03, -1.163e-02, -8.423e-03, -7.526e-03, -1.067e-02, -9.003e-03],\n           [9.392e-03, 1.063e-02, -1.116e-02, -1.000e-02, -1.042e-02, 9.529e-03],\n           ...,\n           [-9.209e-03, -9.911e-03, -7.679e-03, -8.614e-03, 8.606e-03, -9.895e-03],\n           [1.238e-02, -8.797e-03, -8.934e-03, -1.290e-02, -9.552e-03, 8.293e-03],\n           [-8.110e-03, -9.117e-03, -1.040e-02, 8.476e-03, -7.565e-03, 8.080e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.1.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.110e-02, 9.644e-03, -7.050e-03, -8.377e-03, -8.553e-03, -7.717e-03],\n           [-1.073e-02, 8.781e-03, -7.851e-03, 1.314e-02, -1.255e-02, -1.392e-02],\n           [-1.191e-02, 1.043e-02, 9.575e-03, 1.127e-02, -7.980e-03, -1.142e-02],\n           ...,\n           [1.083e-02, -8.423e-03, -1.220e-02, 1.749e-02, -8.713e-03, 1.487e-02],\n           [-8.270e-03, 9.911e-03, -9.659e-03, -1.270e-02, -1.099e-02, -1.297e-02],\n           [-5.783e-03, -7.191e-03, -7.645e-03, 8.018e-03, -7.313e-03, 7.740e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.1.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.308e-02, -1.099e-02, 1.283e-02, -1.448e-02, 1.195e-02, -1.266e-02],\n           [-1.359e-02, -1.051e-02, 1.158e-02, -1.521e-02, -1.403e-02, 1.414e-02],\n           [1.319e-02, 1.201e-02, 1.295e-02, -1.272e-02, -1.281e-02, 1.102e-02],\n           ...,\n           [1.295e-02, 1.014e-02, -1.495e-02, 1.150e-02, -1.151e-02, -1.027e-02],\n           [1.366e-02, 1.516e-02, -1.147e-02, -1.308e-02, -1.202e-02, 1.231e-02],\n           [1.514e-02, -1.088e-02, -1.080e-02, 1.354e-02, -1.231e-02, -1.115e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.1.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-8.408e-03, -1.189e-02, -1.064e-02,  ..., 1.242e-02, -1.192e-02, -1.384e-02],\n           [-1.065e-02, -1.176e-02, -1.662e-02,  ..., 1.032e-02, -1.291e-02, 1.174e-02],\n           [-1.009e-02, -1.279e-02, -1.350e-02,  ..., 1.198e-02, 1.048e-02, -1.524e-02],\n           ...,\n           [-1.156e-02, -1.346e-02, 1.401e-02,  ..., 1.324e-02, 1.765e-02, -1.360e-02],\n           [-1.116e-02, 9.102e-03, 1.313e-02,  ..., -1.269e-02, 1.322e-02, 1.138e-02],\n           [1.125e-02, 1.160e-02, 1.171e-02,  ..., -9.399e-03, 1.052e-02, 9.987e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.2.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[2.785e-02, 3.699e-02, 2.895e-02, -3.017e-02, -4.312e-02, 2.937e-02],\n           [2.243e-02, -2.017e-02, 2.542e-02, 2.220e-02, -2.246e-02, 1.830e-02],\n           [-3.235e-02, -4.242e-02, -2.257e-02, 2.939e-02, 2.388e-02, 2.640e-02],\n           ...,\n           [-1.138e-02, -1.479e-02, 1.279e-02, -1.343e-02, 1.540e-02, -1.238e-02],\n           [-1.192e-02, -1.517e-02, 1.794e-02, 1.356e-02, 1.102e-02, 1.096e-02],\n           [1.562e-02, 1.505e-02, -1.460e-02, -1.500e-02, 1.408e-02, 1.226e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.2.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-3.131e-02, -3.317e-02, 3.311e-02, -4.285e-02, -2.658e-02, -2.393e-02],\n           [1.929e-02, 2.116e-02, 2.020e-02, -2.190e-02, -2.467e-02, 2.190e-02],\n           [-3.687e-02, -3.610e-02, -3.223e-02, -2.313e-02, 2.669e-02, 2.274e-02],\n           ...,\n           [-1.249e-02, -1.508e-02, 1.083e-02, -1.223e-02, 1.237e-02, -1.307e-02],\n           [1.357e-02, -2.603e-02, 1.396e-02, 1.365e-02, 1.442e-02, -1.816e-02],\n           [-1.191e-02, 1.273e-02, 1.156e-02, 1.331e-02, -1.248e-02, 2.075e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.2.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-8.354e-03, -7.843e-03, 6.508e-03, 8.347e-03, 6.153e-03, 6.779e-03],\n           [-5.497e-03, -8.087e-03, -7.084e-03, -6.668e-03, 7.744e-03, 5.699e-03],\n           [-8.064e-03, -6.931e-03, -1.149e-02, 6.645e-03, 6.401e-03, -7.515e-03],\n           ...,\n           [1.212e-02, -1.321e-02, -1.128e-02, -9.056e-03, 1.231e-02, -1.183e-02],\n           [1.164e-02, 1.111e-02, 1.122e-02, 1.297e-02, 1.109e-02, -9.834e-03],\n           [1.167e-02, 1.279e-02, 1.055e-02, -1.131e-02, 1.066e-02, 1.054e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.2.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-9.125e-03, -1.179e-02, 7.538e-03, 7.401e-03, 8.141e-03, 9.048e-03],\n           [-1.006e-02, 1.005e-02, -1.083e-02, 8.194e-03, 8.408e-03, 1.327e-02],\n           [1.121e-02, -8.537e-03, -8.369e-03, -1.173e-02, 8.514e-03, 1.205e-02],\n           ...,\n           [1.123e-02, -1.099e-02, -7.957e-03, -1.333e-02, 1.080e-02, 8.904e-03],\n           [-1.006e-02, -1.221e-02, -1.097e-02, -9.224e-03, 9.109e-03, 9.636e-03],\n           [-6.451e-03, -7.393e-03, -1.042e-02, 5.726e-03, 8.705e-03, 7.221e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.2.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.232e-02, 1.172e-02, 1.154e-02, -1.207e-02, 1.025e-02, 1.051e-02],\n           [1.347e-02, 1.378e-02, -8.644e-03, 1.098e-02, -1.254e-02, -1.291e-02],\n           [1.308e-02, 1.410e-02, 1.169e-02, 1.391e-02, -1.329e-02, -1.403e-02],\n           ...,\n           [-1.026e-02, -1.247e-02, -1.520e-02, -1.198e-02, 1.548e-02, -1.175e-02],\n           [1.570e-02, 1.276e-02, 1.758e-02, -1.349e-02, 1.254e-02, -1.301e-02],\n           [-1.409e-02, -1.291e-02, 1.284e-02, -2.058e-02, 1.152e-02, -1.511e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.2.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[8.469e-03, 9.567e-03, -1.078e-02,  ..., 1.050e-02, -1.226e-02, -1.530e-02],\n           [-1.141e-02, -1.115e-02, 9.842e-03,  ..., -1.564e-02, -9.918e-03, -1.360e-02],\n           [-1.396e-02, -1.025e-02, -1.332e-02,  ..., 1.319e-02, -1.283e-02, -1.064e-02],\n           ...,\n           [-1.397e-02, 1.424e-02, 1.253e-02,  ..., -1.276e-02, 1.283e-02, -1.707e-02],\n           [-1.342e-02, -1.270e-02, -1.114e-02,  ..., -1.260e-02, -1.305e-02, -1.138e-02],\n           [-9.254e-03, 9.323e-03, -1.427e-02,  ..., -1.134e-02, 1.415e-02, 1.056e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.3.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.562e-02, 1.924e-02, 1.581e-02, 1.822e-02, 1.516e-02, -1.903e-02],\n           [-1.581e-02, 1.709e-02, -2.328e-02, 1.273e-02, -2.017e-02, 1.562e-02],\n           [1.694e-02, -2.377e-02, -3.369e-02, 2.014e-02, 1.546e-02, 2.078e-02],\n           ...,\n           [1.160e-02, 1.559e-02, 1.298e-02, -1.328e-02, -1.031e-02, -1.309e-02],\n           [-1.461e-02, -1.935e-02, -1.373e-02, -2.065e-02, 1.591e-02, 1.503e-02],\n           [1.446e-02, -9.895e-03, 1.263e-02, -1.217e-02, -1.299e-02, 1.397e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.3.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.460e-02, 1.947e-02, 1.894e-02, -1.744e-02, -1.418e-02, 1.965e-02],\n           [1.663e-02, 1.904e-02, 2.072e-02, 1.619e-02, 1.492e-02, 1.537e-02],\n           [1.363e-02, 1.743e-02, 2.870e-02, 2.063e-02, 1.289e-02, -1.953e-02],\n           ...,\n           [-1.036e-02, -1.230e-02, -1.264e-02, 1.328e-02, 1.042e-02, -1.492e-02],\n           [-1.624e-02, 1.509e-02, -1.311e-02, 1.195e-02, 1.855e-02, -1.376e-02],\n           [-1.342e-02, -1.423e-02, 1.293e-02, 1.041e-02, -1.318e-02, 1.362e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.3.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.252e-02, 9.056e-03, 1.215e-02, -1.125e-02, 1.163e-02, 1.241e-02],\n           [-1.288e-02, -1.118e-02, 8.957e-03, 9.117e-03, 1.052e-02, -8.255e-03],\n           [9.598e-03, 8.987e-03, -1.350e-02, -1.067e-02, 1.012e-02, -1.049e-02],\n           ...,\n           [-9.613e-03, 1.128e-02, 9.468e-03, 8.934e-03, 1.489e-02, -8.286e-03],\n           [1.128e-02, -1.278e-02, 8.553e-03, 1.080e-02, -1.183e-02, 9.544e-03],\n           [9.628e-03, -1.134e-02, -1.714e-02, -1.167e-02, -9.705e-03, -9.537e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.3.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.012e-02, 9.666e-03, 9.117e-03, 9.262e-03, -1.051e-02, 6.535e-03],\n           [9.087e-03, 9.773e-03, -9.796e-03, 1.302e-02, -8.560e-03, -9.529e-03],\n           [-9.712e-03, -1.155e-02, -1.244e-02, -1.176e-02, -8.568e-03, 1.121e-02],\n           ...,\n           [1.183e-02, -1.158e-02, -1.017e-02, 9.254e-03, -1.111e-02, 1.232e-02],\n           [1.038e-02, 1.041e-02, 9.216e-03, -1.118e-02, 1.427e-02, -9.575e-03],\n           [-6.325e-03, 7.355e-03, -8.202e-03, 8.324e-03, -7.195e-03, 7.286e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.3.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.578e-02, 1.758e-02, -1.456e-02, 1.356e-02, 1.373e-02, -1.086e-02],\n           [1.223e-02, 1.395e-02, -1.241e-02, 1.210e-02, 1.376e-02, 1.269e-02],\n           [-1.347e-02, 1.226e-02, -1.340e-02, 1.299e-02, 1.441e-02, 1.269e-02],\n           ...,\n           [1.065e-02, 8.743e-03, 1.093e-02, 1.029e-02, -1.337e-02, 1.118e-02],\n           [1.131e-02, -1.060e-02, -8.537e-03, -1.176e-02, 1.168e-02, -1.448e-02],\n           [-1.283e-02, 1.224e-02, -1.183e-02, 1.417e-02, -1.053e-02, -1.218e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.3.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.342e-02, -9.514e-03, 9.605e-03,  ..., -9.789e-03, 1.023e-02, 1.136e-02],\n           [-1.161e-02, -1.057e-02, -1.095e-02,  ..., 1.195e-02, -1.359e-02, -1.125e-02],\n           [-1.099e-02, 1.427e-02, 1.182e-02,  ..., 1.476e-02, -1.353e-02, 1.203e-02],\n           ...,\n           [1.707e-02, -1.530e-02, 1.247e-02,  ..., 1.420e-02, -1.598e-02, -2.184e-02],\n           [1.311e-02, -1.307e-02, -1.363e-02,  ..., -1.348e-02, 1.531e-02, -1.324e-02],\n           [1.029e-02, -1.057e-02, 1.137e-02,  ..., -1.267e-02, -9.476e-03, 9.972e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.4.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.888e-02, -1.602e-02, 1.721e-02, 1.904e-02, 1.659e-02, 1.695e-02],\n           [1.648e-02, -1.645e-02, -1.447e-02, 1.300e-02, 1.499e-02, -1.439e-02],\n           [1.279e-02, 1.593e-02, -1.859e-02, -1.605e-02, -1.567e-02, -1.407e-02],\n           ...,\n           [-1.817e-02, -1.460e-02, 1.530e-02, -1.746e-02, 1.480e-02, 1.604e-02],\n           [1.546e-02, -1.366e-02, 1.433e-02, -1.422e-02, -1.472e-02, 1.315e-02],\n           [1.247e-02, -1.431e-02, 2.049e-02, 1.336e-02, 1.765e-02, 2.005e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.4.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.366e-02, -1.933e-02, -1.376e-02, 1.221e-02, -1.715e-02, 1.746e-02],\n           [1.315e-02, 1.372e-02, 1.501e-02, 1.480e-02, -1.456e-02, 2.058e-02],\n           [1.531e-02, 1.591e-02, 1.243e-02, -1.447e-02, -1.518e-02, 1.237e-02],\n           ...,\n           [1.801e-02, 1.392e-02, -1.415e-02, 1.471e-02, -1.398e-02, -1.361e-02],\n           [1.999e-02, 2.330e-02, 1.778e-02, 1.395e-02, -1.686e-02, 1.602e-02],\n           [-1.979e-02, -1.435e-02, 1.860e-02, 1.372e-02, -1.845e-02, -1.196e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.4.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.173e-02, -1.227e-02, -1.200e-02, -1.389e-02, -1.333e-02, 1.401e-02],\n           [-1.299e-02, -1.215e-02, -1.297e-02, 1.099e-02, -1.262e-02, 1.113e-02],\n           [1.191e-02, 1.317e-02, -1.456e-02, 1.576e-02, -1.405e-02, -1.051e-02],\n           ...,\n           [-1.080e-02, 8.720e-03, -1.286e-02, -1.097e-02, 1.009e-02, 1.293e-02],\n           [1.017e-02, -1.278e-02, -1.122e-02, -1.006e-02, -1.528e-02, 9.232e-03],\n           [-8.766e-03, -1.276e-02, 1.086e-02, 1.352e-02, 9.651e-03, 1.493e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.4.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[9.483e-03, 1.447e-02, -1.028e-02, -9.171e-03, -9.094e-03, -1.162e-02],\n           [-1.263e-02, 1.192e-02, -1.273e-02, 1.093e-02, 1.295e-02, -9.071e-03],\n           [-1.067e-02, -1.288e-02, -1.100e-02, 1.299e-02, -1.021e-02, 1.188e-02],\n           ...,\n           [-9.682e-03, 1.528e-02, 1.607e-02, 1.506e-02, 1.249e-02, -9.857e-03],\n           [1.098e-02, -1.335e-02, 1.608e-02, 1.401e-02, 1.517e-02, 1.005e-02],\n           [-9.293e-03, 7.339e-03, 7.679e-03, 8.682e-03, -7.717e-03, -7.267e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.4.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.244e-02, -1.483e-02, -1.128e-02, 1.640e-02, -1.272e-02, 1.183e-02],\n           [1.316e-02, -1.801e-02, -1.562e-02, 1.526e-02, 1.562e-02, -1.820e-02],\n           [-1.229e-02, 1.085e-02, 1.364e-02, -1.334e-02, -1.357e-02, 9.399e-03],\n           ...,\n           [-1.945e-02, 1.610e-02, -1.305e-02, -1.913e-02, 1.671e-02, 1.209e-02],\n           [-1.173e-02, -1.910e-02, 9.949e-03, -1.268e-02, -1.270e-02, 1.181e-02],\n           [-1.331e-02, -1.219e-02, -1.048e-02, 1.164e-02, 1.231e-02, -1.402e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.4.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.080e-02, -9.651e-03, 1.311e-02,  ..., 1.009e-02, 1.006e-02, 1.103e-02],\n           [-1.016e-02, -1.250e-02, 1.147e-02,  ..., -1.324e-02, -1.386e-02, -1.183e-02],\n           [-1.523e-02, -1.288e-02, 1.079e-02,  ..., 1.546e-02, 1.438e-02, -1.369e-02],\n           ...,\n           [1.259e-02, -1.236e-02, -1.550e-02,  ..., 1.686e-02, -1.434e-02, 1.894e-02],\n           [1.408e-02, -1.833e-02, -1.347e-02,  ..., -1.678e-02, 1.074e-02, -2.028e-02],\n           [1.134e-02, 9.163e-03, 1.131e-02,  ..., -1.050e-02, -1.099e-02, -9.300e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.5.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.263e-02, -1.332e-02, -1.260e-02, 1.401e-02, 1.331e-02, -1.184e-02],\n           [-1.788e-02, 1.347e-02, 1.298e-02, -1.405e-02, -1.446e-02, -1.308e-02],\n           [-1.718e-02, 9.888e-03, 1.192e-02, -1.018e-02, -1.265e-02, -1.253e-02],\n           ...,\n           [1.915e-02, 1.590e-02, -1.981e-02, 1.432e-02, -1.646e-02, -1.359e-02],\n           [1.376e-02, 1.627e-02, -2.885e-02, -1.340e-02, 1.505e-02, -1.502e-02],\n           [-1.503e-02, 1.785e-02, 1.706e-02, 1.387e-02, -1.866e-02, -1.961e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.5.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.390e-02, 1.488e-02, 1.468e-02, 1.624e-02, 1.525e-02, 1.359e-02],\n           [-1.660e-02, 1.222e-02, -1.496e-02, -1.215e-02, 1.299e-02, -1.351e-02],\n           [1.417e-02, -9.216e-03, -1.240e-02, -1.417e-02, -1.546e-02, 1.523e-02],\n           ...,\n           [-1.469e-02, -1.788e-02, 1.627e-02, -1.508e-02, -1.674e-02, 1.453e-02],\n           [1.199e-02, 2.074e-02, -3.876e-02, 1.859e-02, 1.959e-02, 1.036e-02],\n           [-2.786e-02, 2.028e-02, 1.854e-02, -1.678e-02, 1.620e-02, 1.698e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.5.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.132e-02, 1.285e-02, 1.364e-02, 1.340e-02, 1.276e-02, -1.009e-02],\n           [-1.794e-02, 1.266e-02, -1.267e-02, 1.397e-02, 1.688e-02, 1.389e-02],\n           [-1.640e-02, -1.437e-02, -1.379e-02, -1.318e-02, -1.034e-02, 1.886e-02],\n           ...,\n           [1.649e-02, -1.476e-02, 1.276e-02, 1.153e-02, 1.095e-02, 1.190e-02],\n           [-1.200e-02, -1.779e-02, -9.544e-03, -1.478e-02, 1.216e-02, -1.317e-02],\n           [-9.094e-03, 1.001e-02, -1.248e-02, 1.176e-02, 1.211e-02, -1.463e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.5.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[7.053e-03, 9.132e-03, -1.165e-02, 1.005e-02, -9.460e-03, 7.301e-03],\n           [-9.171e-03, -1.115e-02, -1.173e-02, 1.134e-02, 1.079e-02, -8.781e-03],\n           [1.085e-02, -1.237e-02, 1.208e-02, 1.327e-02, 1.423e-02, 1.150e-02],\n           ...,\n           [-1.254e-02, -1.381e-02, -1.322e-02, 1.357e-02, 1.455e-02, -1.231e-02],\n           [-9.857e-03, -1.216e-02, 1.202e-02, -1.098e-02, 1.117e-02, 1.283e-02],\n           [9.720e-03, -8.560e-03, 1.144e-02, 9.628e-03, -7.889e-03, 6.744e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.5.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.226e-02, 1.250e-02, 1.002e-02, -1.300e-02, -1.193e-02, 1.147e-02],\n           [-1.799e-02, 1.813e-02, 1.677e-02, -1.363e-02, 1.991e-02, -1.822e-02],\n           [-1.505e-02, 1.391e-02, -1.347e-02, -1.208e-02, 1.241e-02, -1.347e-02],\n           ...,\n           [9.453e-03, 1.039e-02, -8.812e-03, 8.163e-03, 8.522e-03, -8.507e-03],\n           [-1.333e-02, 1.075e-02, -1.328e-02, 1.080e-02, 1.151e-02, 1.591e-02],\n           [1.695e-02, 1.521e-02, -1.625e-02, 1.718e-02, -1.993e-02, -1.421e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.5.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.239e-02, 1.460e-02, -1.056e-02,  ..., 9.102e-03, -1.088e-02, -1.345e-02],\n           [1.675e-02, -1.102e-02, -1.407e-02,  ..., 1.236e-02, 1.396e-02, 1.230e-02],\n           [1.019e-02, 1.136e-02, 1.036e-02,  ..., 1.634e-02, -1.674e-02, -1.187e-02],\n           ...,\n           [2.805e-02, 1.369e-02, -1.421e-02,  ..., 1.990e-02, 2.026e-02, -2.061e-02],\n           [-1.466e-02, 1.386e-02, 1.448e-02,  ..., 1.285e-02, 1.342e-02, 1.373e-02],\n           [-1.070e-02, -1.044e-02, 8.575e-03,  ..., -1.115e-02, -1.672e-02, -9.598e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.6.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.270e-02, 1.468e-02, 1.620e-02, -1.755e-02, -1.384e-02, 1.348e-02],\n           [1.378e-02, 1.498e-02, -1.645e-02, 1.662e-02, 1.720e-02, 1.733e-02],\n           [1.344e-02, -1.532e-02, -1.762e-02, 1.917e-02, -1.477e-02, 1.540e-02],\n           ...,\n           [1.417e-02, 1.402e-02, -1.611e-02, 1.689e-02, 1.749e-02, 1.469e-02],\n           [-1.958e-02, -2.066e-02, 1.595e-02, 1.328e-02, 1.590e-02, 1.564e-02],\n           [-1.506e-02, 1.484e-02, -2.422e-02, -1.355e-02, 1.837e-02, 1.302e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.6.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.463e-02, -1.264e-02, -1.429e-02, 1.674e-02, -1.787e-02, 1.695e-02],\n           [1.277e-02, -1.518e-02, 1.912e-02, 1.541e-02, 1.575e-02, -1.750e-02],\n           [1.845e-02, 2.066e-02, 1.854e-02, -1.605e-02, -1.451e-02, -1.750e-02],\n           ...,\n           [-1.420e-02, -1.624e-02, 1.418e-02, 1.356e-02, -1.662e-02, -1.605e-02],\n           [1.830e-02, -1.292e-02, 1.590e-02, -1.701e-02, 1.779e-02, 1.539e-02],\n           [1.318e-02, 1.266e-02, -2.913e-02, 1.222e-02, 1.599e-02, -1.566e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.6.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.374e-02, -1.490e-02, -1.287e-02, -1.318e-02, -1.254e-02, -1.345e-02],\n           [-1.542e-02, -1.395e-02, -1.828e-02, -1.672e-02, 1.604e-02, 1.398e-02],\n           [-1.596e-02, 1.384e-02, -1.198e-02, -1.223e-02, 1.135e-02, 1.869e-02],\n           ...,\n           [-8.507e-03, 7.557e-03, -8.629e-03, 8.682e-03, 8.446e-03, -8.675e-03],\n           [-7.881e-03, -7.561e-03, 7.702e-03, -8.293e-03, 6.634e-03, 7.572e-03],\n           [9.819e-03, -9.270e-03, 7.736e-03, 1.022e-02, 7.751e-03, -8.881e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.6.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[8.858e-03, -7.263e-03, 9.987e-03, -9.300e-03, 8.720e-03, 7.587e-03],\n           [-1.025e-02, 1.055e-02, 9.209e-03, -1.327e-02, -1.384e-02, -8.606e-03],\n           [-1.199e-02, 1.334e-02, -1.263e-02, -1.044e-02, 1.211e-02, -1.101e-02],\n           ...,\n           [1.537e-02, 1.317e-02, 1.427e-02, -1.313e-02, -1.187e-02, 1.414e-02],\n           [-1.429e-02, 1.085e-02, -1.154e-02, 1.303e-02, 1.225e-02, 1.020e-02],\n           [-9.010e-03, -9.674e-03, -1.006e-02, -9.399e-03, -8.415e-03, -7.034e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.6.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.126e-02, -1.306e-02, -1.154e-02, -1.298e-02, 1.301e-02, 1.067e-02],\n           [-1.320e-02, 1.319e-02, -1.836e-02, 1.444e-02, 1.460e-02, 1.263e-02],\n           [1.540e-02, 1.310e-02, -1.354e-02, -1.286e-02, 1.368e-02, 1.366e-02],\n           ...,\n           [-1.297e-02, 1.349e-02, 1.692e-02, -1.396e-02, -1.517e-02, 1.404e-02],\n           [1.767e-02, 1.889e-02, 1.182e-02, -1.427e-02, -1.414e-02, -1.377e-02],\n           [1.727e-02, -1.461e-02, 1.991e-02, 1.826e-02, 1.848e-02, 2.031e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.6.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.059e-02, -9.460e-03, 1.187e-02,  ..., -1.244e-02, 1.058e-02, -1.093e-02],\n           [1.411e-02, -1.675e-02, 1.250e-02,  ..., -1.390e-02, 1.254e-02, -1.222e-02],\n           [1.715e-02, -1.319e-02, -1.414e-02,  ..., -1.353e-02, 1.552e-02, 1.509e-02],\n           ...,\n           [-1.576e-02, 1.415e-02, -1.437e-02,  ..., -1.439e-02, 1.236e-02, -1.534e-02],\n           [-1.514e-02, -1.307e-02, -1.491e-02,  ..., 1.165e-02, -1.455e-02, -1.564e-02],\n           [1.444e-02, -1.004e-02, -1.697e-02,  ..., 1.026e-02, 8.148e-03, 1.119e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.7.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.199e-02, 1.595e-02, -1.631e-02, 1.423e-02, -1.139e-02, 1.816e-02],\n           [-1.279e-02, -1.436e-02, 1.529e-02, 1.296e-02, -1.501e-02, -1.295e-02],\n           [-1.456e-02, 1.846e-02, 3.162e-02, 1.761e-02, 1.012e-02, 1.785e-02],\n           ...,\n           [-1.651e-02, -1.511e-02, 2.068e-02, -1.501e-02, 1.595e-02, 1.496e-02],\n           [-1.987e-02, 1.877e-02, 1.591e-02, 1.488e-02, -1.865e-02, -1.970e-02],\n           [1.420e-02, -1.333e-02, 1.582e-02, -1.617e-02, 1.682e-02, 1.605e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.7.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.228e-02, -1.085e-02, -1.217e-02, 1.480e-02, -1.712e-02, 1.219e-02],\n           [-1.244e-02, -1.502e-02, 1.397e-02, -1.357e-02, -1.334e-02, 1.324e-02],\n           [1.505e-02, -1.262e-02, 3.799e-02, 1.071e-02, -2.144e-02, -1.447e-02],\n           ...,\n           [1.851e-02, -1.854e-02, 1.607e-02, 1.387e-02, 1.544e-02, -1.782e-02],\n           [-1.790e-02, -1.331e-02, 1.949e-02, 1.680e-02, 1.637e-02, -1.608e-02],\n           [1.376e-02, 1.747e-02, -1.414e-02, 1.740e-02, -1.851e-02, 1.628e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.7.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.714e-02, -1.273e-02, 1.151e-02, 1.151e-02, -1.559e-02, 1.023e-02],\n           [1.283e-02, -1.249e-02, 1.212e-02, 1.633e-02, 1.380e-02, -1.295e-02],\n           [-1.849e-02, 1.372e-02, -1.117e-02, -1.326e-02, 1.479e-02, 1.266e-02],\n           ...,\n           [-1.287e-02, 8.018e-03, -1.249e-02, -8.789e-03, 9.903e-03, 9.552e-03],\n           [-9.193e-03, 9.758e-03, -9.056e-03, 1.194e-02, -1.495e-02, 8.537e-03],\n           [-1.365e-02, -1.301e-02, -1.089e-02, -9.857e-03, 9.010e-03, 1.178e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.7.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-9.346e-03, 9.605e-03, -7.751e-03, -9.125e-03, 6.088e-03, -1.049e-02],\n           [-1.163e-02, 9.056e-03, -1.026e-02, -1.012e-02, 8.698e-03, -1.019e-02],\n           [1.376e-02, 1.403e-02, -1.391e-02, -1.041e-02, 1.323e-02, 1.083e-02],\n           ...,\n           [-1.093e-02, -1.701e-02, 1.327e-02, -1.193e-02, 1.402e-02, 1.022e-02],\n           [9.529e-03, 1.266e-02, 1.025e-02, 1.276e-02, -1.314e-02, 9.247e-03],\n           [-9.583e-03, 9.155e-03, 8.018e-03, -1.029e-02, -8.728e-03, -8.980e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.7.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.218e-02, -1.540e-02, -1.342e-02, -1.247e-02, 1.171e-02, -1.156e-02],\n           [-1.741e-02, 1.813e-02, 1.456e-02, -1.617e-02, -1.938e-02, 9.819e-03],\n           [-1.173e-02, -1.278e-02, 1.493e-02, -1.284e-02, 1.104e-02, -1.152e-02],\n           ...,\n           [1.363e-02, -1.120e-02, 1.091e-02, 1.045e-02, 1.158e-02, 9.979e-03],\n           [1.892e-02, -1.591e-02, -1.470e-02, -1.276e-02, 1.470e-02, -1.691e-02],\n           [1.307e-02, -1.157e-02, 1.561e-02, -9.659e-03, 1.210e-02, 1.353e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.7.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.190e-02, -1.492e-02, 1.236e-02,  ..., 1.672e-02, 1.557e-02, 1.145e-02],\n           [1.184e-02, -1.289e-02, -1.096e-02,  ..., 1.154e-02, -2.415e-02, 1.235e-02],\n           [-1.277e-02, 1.403e-02, 1.505e-02,  ..., -1.653e-02, 1.254e-02, 1.123e-02],\n           ...,\n           [1.401e-02, 1.504e-02, -1.294e-02,  ..., 1.262e-02, 1.761e-02, 1.104e-02],\n           [-1.352e-02, 1.431e-02, 1.599e-02,  ..., 1.514e-02, -2.277e-02, -1.279e-02],\n           [-1.215e-02, 1.215e-02, 1.215e-02,  ..., 1.200e-02, -1.262e-02, -9.476e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.8.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.453e-02, 1.929e-02, 2.292e-02, -1.468e-02, 1.333e-02, -1.534e-02],\n           [-2.032e-02, -1.534e-02, -1.385e-02, 1.419e-02, -1.535e-02, -1.686e-02],\n           [-1.918e-02, -1.543e-02, 1.309e-02, 1.747e-02, -1.425e-02, -1.584e-02],\n           ...,\n           [1.944e-02, 1.393e-02, 1.825e-02, -1.587e-02, -1.591e-02, -1.729e-02],\n           [-1.505e-02, 1.554e-02, 1.489e-02, -1.816e-02, -1.746e-02, 1.351e-02],\n           [-1.335e-02, -1.581e-02, -1.529e-02, 1.246e-02, -1.878e-02, 1.648e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.8.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.374e-02, 1.417e-02, 1.398e-02, -1.531e-02, -2.332e-02, 1.330e-02],\n           [1.456e-02, -1.450e-02, -1.924e-02, 1.492e-02, -1.598e-02, -1.524e-02],\n           [-2.365e-02, -1.512e-02, -1.501e-02, -1.199e-02, 1.479e-02, -1.604e-02],\n           ...,\n           [-1.680e-02, -1.328e-02, 1.334e-02, -1.346e-02, -1.912e-02, 1.485e-02],\n           [-1.418e-02, -1.383e-02, -1.534e-02, -1.205e-02, 1.544e-02, 1.325e-02],\n           [-1.321e-02, 1.332e-02, -1.412e-02, 2.162e-02, 1.643e-02, -1.463e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.8.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.193e-02, -1.287e-02, 1.337e-02, 1.897e-02, -1.232e-02, -1.038e-02],\n           [-1.388e-02, -1.321e-02, 1.402e-02, 1.607e-02, 1.252e-02, 1.044e-02],\n           [-1.283e-02, -1.146e-02, 1.210e-02, -1.243e-02, -1.283e-02, -1.489e-02],\n           ...,\n           [-1.262e-02, -1.291e-02, 1.035e-02, -1.364e-02, -1.073e-02, 1.103e-02],\n           [-1.166e-02, 1.308e-02, -1.091e-02, -1.031e-02, -1.147e-02, -1.131e-02],\n           [1.396e-02, 1.118e-02, -1.163e-02, 9.308e-03, 1.354e-02, -1.007e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.8.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.244e-02, 7.912e-03, 1.061e-02, 1.157e-02, -9.506e-03, -8.530e-03],\n           [1.257e-02, -8.736e-03, -1.091e-02, 1.004e-02, 1.092e-02, -9.171e-03],\n           [-1.613e-02, 9.857e-03, 1.166e-02, 1.508e-02, -1.141e-02, -1.124e-02],\n           ...,\n           [1.189e-02, -1.277e-02, 2.083e-02, -1.628e-02, -1.527e-02, 1.319e-02],\n           [1.159e-02, -9.331e-03, 1.542e-02, -9.148e-03, 1.237e-02, -1.459e-02],\n           [-1.230e-02, 9.895e-03, 1.074e-02, -8.438e-03, 8.408e-03, 7.866e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.8.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.239e-02, 1.476e-02, 1.389e-02, 1.305e-02, 1.172e-02, -1.166e-02],\n           [-1.845e-02, 1.987e-02, -1.231e-02, -1.420e-02, -1.485e-02, 1.188e-02],\n           [-1.520e-02, -1.730e-02, 1.851e-02, -1.524e-02, 1.495e-02, 1.337e-02],\n           ...,\n           [1.443e-02, 1.511e-02, -1.115e-02, -1.234e-02, -1.242e-02, 1.092e-02],\n           [-1.758e-02, 1.619e-02, -1.312e-02, 1.537e-02, -1.617e-02, -1.591e-02],\n           [1.077e-02, -1.105e-02, -1.528e-02, -1.072e-02, 1.707e-02, 1.443e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.8.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.331e-02, -1.170e-02, -1.315e-02,  ..., 9.659e-03, 1.028e-02, -1.263e-02],\n           [-1.299e-02, 1.212e-02, -1.107e-02,  ..., -1.146e-02, 1.174e-02, -1.805e-02],\n           [1.132e-02, -1.967e-02, 1.584e-02,  ..., -1.591e-02, 9.476e-03, 1.217e-02],\n           ...,\n           [1.472e-02, -1.197e-02, 1.292e-02,  ..., 1.590e-02, 1.140e-02, 1.195e-02],\n           [1.212e-02, 1.520e-02, -1.462e-02,  ..., -1.923e-02, -1.547e-02, 1.417e-02],\n           [-1.436e-02, -1.019e-02, -9.659e-03,  ..., -8.827e-03, -1.337e-02, 1.221e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.9.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.341e-02, 1.883e-02, -1.498e-02, -1.521e-02, -1.584e-02, -1.559e-02],\n           [1.324e-02, 1.767e-02, 1.519e-02, 1.666e-02, 1.446e-02, 1.553e-02],\n           [-1.462e-02, 1.665e-02, -1.505e-02, -1.648e-02, 1.703e-02, -1.420e-02],\n           ...,\n           [1.184e-02, 1.454e-02, -1.440e-02, -1.553e-02, -1.826e-02, 1.465e-02],\n           [-1.669e-02, -1.639e-02, -1.672e-02, 1.675e-02, -1.767e-02, -1.797e-02],\n           [-1.672e-02, 1.495e-02, -1.399e-02, 1.186e-02, -1.843e-02, -1.544e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.9.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.724e-02, 1.521e-02, -1.976e-02, -1.330e-02, 1.517e-02, 1.675e-02],\n           [-1.987e-02, -1.266e-02, 3.253e-02, -1.491e-02, 1.634e-02, 1.761e-02],\n           [1.514e-02, 2.069e-02, -1.793e-02, -1.776e-02, -1.907e-02, 2.036e-02],\n           ...,\n           [1.511e-02, -1.462e-02, -1.234e-02, 1.485e-02, 1.653e-02, -1.398e-02],\n           [-1.923e-02, 1.498e-02, 1.726e-02, 1.353e-02, -1.219e-02, 1.364e-02],\n           [-1.521e-02, 1.660e-02, -1.762e-02, 1.308e-02, -1.553e-02, 1.500e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.9.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.276e-02, -1.181e-02, 1.025e-02, -1.388e-02, 1.492e-02, 1.176e-02],\n           [1.532e-02, -1.200e-02, -1.336e-02, -1.366e-02, 1.428e-02, 1.304e-02],\n           [-1.062e-02, 1.087e-02, -1.299e-02, -1.129e-02, 1.349e-02, -1.417e-02],\n           ...,\n           [-9.781e-03, -1.199e-02, 1.430e-02, -1.091e-02, 1.518e-02, -1.237e-02],\n           [-1.440e-02, -1.564e-02, -1.066e-02, 1.284e-02, 1.232e-02, 1.480e-02],\n           [1.186e-02, 1.485e-02, -1.660e-02, -1.173e-02, 1.049e-02, 1.173e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.9.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.192e-02, -1.042e-02, -1.039e-02, 9.102e-03, 9.819e-03, -1.107e-02],\n           [-9.842e-03, 7.668e-03, 1.147e-02, 9.865e-03, 9.239e-03, 1.184e-02],\n           [-1.389e-02, -1.318e-02, 1.496e-02, -1.300e-02, -1.234e-02, 1.144e-02],\n           ...,\n           [-1.050e-02, 1.208e-02, 1.862e-02, -1.161e-02, -1.028e-02, -1.067e-02],\n           [-1.194e-02, -9.804e-03, -1.454e-02, 1.124e-02, 1.354e-02, -1.193e-02],\n           [-1.450e-02, -1.158e-02, -1.022e-02, 8.980e-03, -8.270e-03, 8.995e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.9.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.246e-02, 1.386e-02, 1.220e-02, -1.790e-02, 1.488e-02, -1.417e-02],\n           [1.160e-02, 9.933e-03, 1.135e-02, -1.148e-02, 1.131e-02, 1.286e-02],\n           [-1.120e-02, -1.575e-02, 1.338e-02, -1.129e-02, 1.305e-02, 1.554e-02],\n           ...,\n           [-1.176e-02, -1.141e-02, -1.097e-02, 1.151e-02, -1.144e-02, 1.328e-02],\n           [1.491e-02, 1.176e-02, 1.199e-02, -1.266e-02, 1.056e-02, -1.060e-02],\n           [-2.150e-02, -1.695e-02, -1.292e-02, -1.412e-02, -1.659e-02, -1.610e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.9.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.581e-02, 1.108e-02, 1.788e-02,  ..., 1.297e-02, -1.399e-02, 1.115e-02],\n           [1.551e-02, 1.048e-02, 1.249e-02,  ..., 1.733e-02, -1.601e-02, -1.381e-02],\n           [1.570e-02, 1.703e-02, 1.941e-02,  ..., 1.467e-02, 1.354e-02, 1.927e-02],\n           ...,\n           [1.553e-02, -1.585e-02, 1.340e-02,  ..., -1.105e-02, 1.706e-02, -1.503e-02],\n           [-1.665e-02, 1.549e-02, -1.746e-02,  ..., -1.430e-02, 1.630e-02, -1.656e-02],\n           [1.935e-02, 1.078e-02, 9.995e-03,  ..., 1.395e-02, -1.451e-02, 1.231e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.10.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.247e-02, -1.723e-02, -1.480e-02, -1.617e-02, -1.293e-02, -1.537e-02],\n           [-1.491e-02, -1.476e-02, 1.620e-02, 1.463e-02, 1.447e-02, 1.546e-02],\n           [-1.514e-02, -1.299e-02, -1.530e-02, 1.510e-02, 2.036e-02, 1.608e-02],\n           ...,\n           [1.668e-02, -3.038e-02, 1.192e-02, -1.554e-02, 1.425e-02, -2.480e-02],\n           [-1.607e-02, -1.608e-02, 1.473e-02, 2.264e-02, 1.287e-02, -1.392e-02],\n           [1.441e-02, -1.593e-02, -1.336e-02, -1.194e-02, -1.533e-02, -1.454e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.10.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.382e-02, -1.672e-02, 1.354e-02, 1.686e-02, 1.714e-02, 1.396e-02],\n           [1.287e-02, 1.689e-02, -1.743e-02, 1.711e-02, -1.377e-02, 1.805e-02],\n           [-1.360e-02, 1.492e-02, 1.546e-02, 1.221e-02, -1.811e-02, 1.764e-02],\n           ...,\n           [1.680e-02, -1.819e-02, 1.643e-02, -1.869e-02, -1.405e-02, 1.788e-02],\n           [1.697e-02, -1.518e-02, -1.590e-02, -1.219e-02, -1.516e-02, -1.472e-02],\n           [-1.237e-02, -1.553e-02, -1.470e-02, -1.480e-02, -1.382e-02, 1.450e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.10.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.169e-02, -1.298e-02, -1.392e-02, -1.556e-02, 1.215e-02, 1.276e-02],\n           [-1.056e-02, 1.309e-02, 1.039e-02, -1.279e-02, 1.985e-02, 1.376e-02],\n           [-1.337e-02, 1.350e-02, -1.313e-02, 1.173e-02, -1.102e-02, 1.185e-02],\n           ...,\n           [1.528e-02, -1.067e-02, 1.142e-02, -1.241e-02, -1.328e-02, 1.017e-02],\n           [1.301e-02, -1.384e-02, -1.265e-02, -1.286e-02, -1.083e-02, -1.167e-02],\n           [1.156e-02, -1.120e-02, -9.422e-03, -1.457e-02, 1.572e-02, 1.432e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.10.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.418e-02, -9.483e-03, -1.141e-02, -1.302e-02, 1.558e-02, 8.614e-03],\n           [9.407e-03, -1.163e-02, -1.352e-02, 1.145e-02, -1.253e-02, 1.217e-02],\n           [-1.488e-02, -1.175e-02, 1.235e-02, -1.368e-02, 1.163e-02, 1.010e-02],\n           ...,\n           [1.360e-02, 1.102e-02, -1.482e-02, 1.488e-02, 1.192e-02, 1.010e-02],\n           [-1.067e-02, 1.160e-02, 1.227e-02, -1.025e-02, -1.651e-02, -1.025e-02],\n           [-1.400e-02, -8.652e-03, -1.482e-02, 1.077e-02, 1.271e-02, -8.873e-03]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.10.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.311e-02, -1.677e-02, -1.246e-02, 1.262e-02, -1.288e-02, 1.671e-02],\n           [-1.176e-02, -1.616e-02, -1.301e-02, 1.148e-02, -1.448e-02, -1.115e-02],\n           [1.198e-02, 1.091e-02, -1.022e-02, 1.436e-02, -1.382e-02, -1.682e-02],\n           ...,\n           [1.368e-02, 1.480e-02, 1.559e-02, -1.539e-02, 1.371e-02, -1.649e-02],\n           [-1.379e-02, -1.375e-02, 1.642e-02, 1.654e-02, -1.258e-02, 1.362e-02],\n           [-1.233e-02, 1.307e-02, 1.296e-02, 1.082e-02, -1.144e-02, -1.424e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.10.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.102e-02, -1.331e-02, 1.874e-02,  ..., 1.334e-02, 1.170e-02, -1.090e-02],\n           [-1.282e-02, -1.099e-02, -1.313e-02,  ..., -1.455e-02, -1.657e-02, -1.050e-02],\n           [1.700e-02, 1.078e-02, 1.331e-02,  ..., 1.311e-02, 1.392e-02, -1.163e-02],\n           ...,\n           [-1.495e-02, -1.258e-02, -1.447e-02,  ..., -1.419e-02, 1.671e-02, -1.324e-02],\n           [1.720e-02, -1.381e-02, 1.689e-02,  ..., -1.269e-02, 1.056e-02, 1.491e-02],\n           [1.061e-02, -1.054e-02, -1.158e-02,  ..., -1.176e-02, 1.213e-02, -1.348e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.11.attention.self.query': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.376e-02, 2.637e-02, 1.596e-02, -1.537e-02, -1.625e-02, -1.653e-02],\n           [-2.135e-02, 2.615e-02, 1.750e-02, -1.573e-02, -1.875e-02, 1.732e-02],\n           [1.704e-02, 2.177e-02, 1.499e-02, -1.543e-02, 1.433e-02, 1.494e-02],\n           ...,\n           [-1.418e-02, 1.454e-02, 1.227e-02, -1.545e-02, 1.349e-02, -1.528e-02],\n           [-1.553e-02, 1.837e-02, -1.384e-02, -1.438e-02, -1.466e-02, 1.645e-02],\n           [-1.700e-02, -2.144e-02, -1.878e-02, 1.431e-02, -1.984e-02, -1.671e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.11.attention.self.key': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.481e-02, -1.459e-02, 1.811e-02, 1.575e-02, -1.410e-02, 1.826e-02],\n           [-1.320e-02, 1.828e-02, 1.593e-02, 1.660e-02, -1.370e-02, -1.299e-02],\n           [-1.560e-02, 1.624e-02, -1.460e-02, -1.299e-02, -1.324e-02, 1.428e-02],\n           ...,\n           [-1.636e-02, 1.668e-02, 1.131e-02, 1.782e-02, -1.369e-02, -1.282e-02],\n           [-1.273e-02, 1.538e-02, -1.306e-02, -1.313e-02, -1.651e-02, 2.118e-02],\n           [1.758e-02, 2.281e-02, 5.151e-02, -1.484e-02, -1.376e-02, -1.465e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.11.attention.self.value': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.545e-02, -1.317e-02, -1.086e-02, -1.345e-02, -1.044e-02, -1.208e-02],\n           [1.573e-02, 1.639e-02, -1.430e-02, 1.808e-02, -1.506e-02, -1.208e-02],\n           [1.819e-02, 1.624e-02, -1.522e-02, -1.291e-02, 1.237e-02, 1.411e-02],\n           ...,\n           [-1.248e-02, -1.810e-02, -1.521e-02, -1.584e-02, 1.266e-02, 1.121e-02],\n           [1.325e-02, -1.460e-02, 1.203e-02, -1.308e-02, 1.337e-02, -1.493e-02],\n           [-1.888e-02, 1.605e-02, 1.447e-02, 1.350e-02, -1.364e-02, -1.584e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.11.attention.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.035e-02, -1.321e-02, 1.538e-02, -1.403e-02, 2.107e-02, -1.376e-02],\n           [-1.208e-02, -1.427e-02, 1.306e-02, 1.405e-02, 1.369e-02, -1.057e-02],\n           [-1.839e-02, 1.194e-02, 1.053e-02, 1.380e-02, 1.214e-02, -1.198e-02],\n           ...,\n           [-1.313e-02, 1.220e-02, 1.174e-02, 1.405e-02, 1.173e-02, 1.298e-02],\n           [1.729e-02, 1.358e-02, 9.789e-03, -1.385e-02, -1.437e-02, -1.144e-02],\n           [1.144e-02, 1.241e-02, -1.439e-02, 1.151e-02, 1.678e-02, 1.325e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.11.intermediate.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[-1.299e-02, 1.326e-02, 1.109e-02, -1.384e-02, -1.096e-02, 1.552e-02],\n           [1.515e-02, 1.247e-02, -1.437e-02, -1.675e-02, 1.386e-02, -1.393e-02],\n           [-1.843e-02, 1.492e-02, 1.736e-02, -1.327e-02, -1.207e-02, 1.988e-02],\n           ...,\n           [-1.300e-02, -1.801e-02, 1.331e-02, -1.434e-02, 1.604e-02, -1.512e-02],\n           [1.255e-02, 1.385e-02, 1.262e-02, -1.255e-02, 1.328e-02, 1.171e-02],\n           [1.493e-02, -1.091e-02, 1.026e-02, -1.379e-02, 1.378e-02, 1.334e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'bert.encoder.layer.11.output.dense': {'data_type': 'int',\n   'bits': 4,\n   'group_size': 128,\n   'sym': True,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int',\n   'scale': tensor([[1.036e-02, -1.142e-02, 9.964e-03,  ..., -1.730e-02, 1.261e-02, 1.176e-02],\n           [-1.169e-02, 1.257e-02, 1.194e-02,  ..., 1.144e-02, -1.108e-02, 1.551e-02],\n           [1.501e-02, 1.082e-02, -1.390e-02,  ..., -1.080e-02, -1.305e-02, 1.579e-02],\n           ...,\n           [-1.309e-02, 1.254e-02, 1.149e-02,  ..., 1.438e-02, -1.424e-02, -1.309e-02],\n           [1.530e-02, 1.400e-02, 1.320e-02,  ..., -1.253e-02, -1.218e-02, -1.418e-02],\n           [-1.266e-02, -1.376e-02, 1.582e-02,  ..., -1.190e-02, -1.231e-02, 1.070e-02]],\n          dtype=torch.float16),\n   'zp': tensor([[8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           ...,\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00],\n           [8.000e+00, 8.000e+00, 8.000e+00,  ..., 8.000e+00, 8.000e+00, 8.000e+00]],\n          dtype=torch.float16)},\n  'classifier': {'data_type': 'float',\n   'bits': 16,\n   'group_size': None,\n   'sym': None,\n   'scale_dtype': torch.float16,\n   'act_bits': 16,\n   'act_group_size': 128,\n   'act_sym': True,\n   'act_dynamic': True,\n   'act_data_type': 'int'}})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"auto_round_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"auto_round_fine_tuned\",torch_dtype=torch.float16)\nprint_size_of_model(auto_round_fine_tuned)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T17:06:54.537318Z","iopub.execute_input":"2024-12-19T17:06:54.537982Z","iopub.status.idle":"2024-12-19T17:06:54.977877Z","shell.execute_reply.started":"2024-12-19T17:06:54.537926Z","shell.execute_reply":"2024-12-19T17:06:54.976843Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Size (KB): 217875.845\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"quantized_model = torch.quantization.quantize_dynamic(\n    model_fine_tuned, {torch.nn.Linear}, dtype=torch.qint8,\n).to('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:43:41.042248Z","iopub.execute_input":"2024-12-19T16:43:41.042977Z","iopub.status.idle":"2024-12-19T16:43:42.714844Z","shell.execute_reply.started":"2024-12-19T16:43:41.042925Z","shell.execute_reply":"2024-12-19T16:43:42.713745Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def print_size_of_model(model):\n    torch.save(model.state_dict(), \"temp_delme.p\")\n    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n    os.remove('temp_delme.p')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:18:27.853062Z","iopub.execute_input":"2024-12-22T16:18:27.853893Z","iopub.status.idle":"2024-12-22T16:18:27.857825Z","shell.execute_reply.started":"2024-12-22T16:18:27.853857Z","shell.execute_reply":"2024-12-22T16:18:27.856955Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"fine_tune_trainer = Trainer( \n    model_fine_tuned, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) \n\nquntised_trainer = Trainer( \n    quantized_model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics , \n) \n\nautoround_trainer = Trainer( \n    auto_round_fine_tuned, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(model_fine_tuned), fine_tune_trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:44:07.921979Z","iopub.execute_input":"2024-12-19T16:44:07.922435Z","iopub.status.idle":"2024-12-19T16:49:05.212266Z","shell.execute_reply.started":"2024-12-19T16:44:07.922399Z","shell.execute_reply":"2024-12-19T16:49:05.210873Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Size (KB): 435672.965\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [54/54 04:41]\n    </div>\n    "},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(None,\n {'eval_loss': 0.10942327231168747,\n  'eval_model_preparation_time': 0.0037,\n  'eval_precision': 0.8816678313533659,\n  'eval_recall': 0.8984096843104676,\n  'eval_f1': 0.8899600282153775,\n  'eval_accuracy': 0.9746219183758028,\n  'eval_runtime': 296.4786,\n  'eval_samples_per_second': 11.647,\n  'eval_steps_per_second': 0.182})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"print_size_of_model(quantized_model), quntised_trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:49:05.214401Z","iopub.execute_input":"2024-12-19T16:49:05.214914Z","iopub.status.idle":"2024-12-19T16:52:49.708246Z","shell.execute_reply.started":"2024-12-19T16:49:05.214863Z","shell.execute_reply":"2024-12-19T16:52:49.707158Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Size (KB): 180905.751\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [54/54 03:31]\n    </div>\n    "},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(None,\n {'eval_loss': 0.18233591318130493,\n  'eval_model_preparation_time': 0.0036,\n  'eval_precision': 0.8597059556441565,\n  'eval_recall': 0.8188938998338476,\n  'eval_f1': 0.838803792851933,\n  'eval_accuracy': 0.9648504937504316,\n  'eval_runtime': 223.7837,\n  'eval_samples_per_second': 15.43,\n  'eval_steps_per_second': 0.241})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print_size_of_model(auto_round_fine_tuned), autoround_trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T17:12:54.628083Z","iopub.execute_input":"2024-12-19T17:12:54.628464Z","iopub.status.idle":"2024-12-19T17:17:32.203899Z","shell.execute_reply.started":"2024-12-19T17:12:54.62843Z","shell.execute_reply":"2024-12-19T17:17:32.202769Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Size (KB): 217875.845\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(None,\n {'eval_loss': 0.10924585163593292,\n  'eval_model_preparation_time': 0.0046,\n  'eval_precision': 0.8755230125523012,\n  'eval_recall': 0.8940185141229527,\n  'eval_f1': 0.8846741045214328,\n  'eval_accuracy': 0.9735342863061943,\n  'eval_runtime': 277.2059,\n  'eval_samples_per_second': 12.456,\n  'eval_steps_per_second': 0.195})"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"print_size_of_model(model_fine_tuned), print_size_of_model(quantized_model), print_size_of_model(auto_round_fine_tuned)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T17:09:30.219459Z","iopub.execute_input":"2024-12-19T17:09:30.21986Z","iopub.status.idle":"2024-12-19T17:09:31.889427Z","shell.execute_reply.started":"2024-12-19T17:09:30.219826Z","shell.execute_reply":"2024-12-19T17:09:31.888343Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"Size (KB): 435672.965\nSize (KB): 180905.751\nSize (KB): 217875.845\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"(None, None, None)"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LORA\n","metadata":{}},{"cell_type":"markdown","source":"## using standard bert again to fine tune and compared result to earlier fine tuning","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, TaskType\nfrom peft import get_peft_model\n\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS, r=1, lora_alpha=1, lora_dropout=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:05:27.422703Z","iopub.execute_input":"2024-12-22T16:05:27.423467Z","iopub.status.idle":"2024-12-22T16:05:27.427837Z","shell.execute_reply.started":"2024-12-22T16:05:27.423431Z","shell.execute_reply":"2024-12-22T16:05:27.426924Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\nmodel = AutoModelForTokenClassification.from_pretrained(\n    'bert-base-uncased', num_labels = 9\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:05:27.703052Z","iopub.execute_input":"2024-12-22T16:05:27.70341Z","iopub.status.idle":"2024-12-22T16:05:27.864478Z","shell.execute_reply.started":"2024-12-22T16:05:27.703382Z","shell.execute_reply":"2024-12-22T16:05:27.863773Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"peft_model = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:24:25.74047Z","iopub.execute_input":"2024-12-22T16:24:25.740845Z","iopub.status.idle":"2024-12-22T16:24:25.775827Z","shell.execute_reply.started":"2024-12-22T16:24:25.740815Z","shell.execute_reply":"2024-12-22T16:24:25.774943Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/mapping.py:185: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'bert-base-uncased' to 'None'. Please ensure that the correct base model is loaded when loading this checkpoint.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"args = TrainingArguments( \n\"lora-ner\",\nevaluation_strategy = \"epoch\", \nlearning_rate=1e-3, \nper_device_train_batch_size=64, \nper_device_eval_batch_size=64, \nnum_train_epochs=5, \nweight_decay=0.01\n) \ntrainer = Trainer( \n    model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:07.230278Z","iopub.execute_input":"2024-12-22T16:09:07.230736Z","iopub.status.idle":"2024-12-22T16:09:07.276768Z","shell.execute_reply.started":"2024-12-22T16:09:07.230681Z","shell.execute_reply":"2024-12-22T16:09:07.275945Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n/tmp/ipykernel_23/152047694.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:09:08.685944Z","iopub.execute_input":"2024-12-22T16:09:08.686713Z","iopub.status.idle":"2024-12-22T16:14:58.090433Z","shell.execute_reply.started":"2024-12-22T16:09:08.686677Z","shell.execute_reply":"2024-12-22T16:14:58.089605Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [550/550 05:48, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.115601</td>\n      <td>0.796979</td>\n      <td>0.820338</td>\n      <td>0.808490</td>\n      <td>0.965556</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.091624</td>\n      <td>0.843955</td>\n      <td>0.865197</td>\n      <td>0.854444</td>\n      <td>0.972742</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.077937</td>\n      <td>0.862764</td>\n      <td>0.885446</td>\n      <td>0.873958</td>\n      <td>0.976082</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.074616</td>\n      <td>0.863542</td>\n      <td>0.888466</td>\n      <td>0.875827</td>\n      <td>0.976889</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.131500</td>\n      <td>0.073099</td>\n      <td>0.868504</td>\n      <td>0.891822</td>\n      <td>0.880009</td>\n      <td>0.977407</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=550, training_loss=0.12807010824030096, metrics={'train_runtime': 348.6842, 'train_samples_per_second': 201.343, 'train_steps_per_second': 1.577, 'total_flos': 2237676578175600.0, 'train_loss': 0.12807010824030096, 'epoch': 5.0})"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:15:19.346766Z","iopub.execute_input":"2024-12-22T16:15:19.347111Z","iopub.status.idle":"2024-12-22T16:15:28.494412Z","shell.execute_reply.started":"2024-12-22T16:15:19.347079Z","shell.execute_reply":"2024-12-22T16:15:28.493546Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27/27 00:07]\n    </div>\n    "},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.0965961217880249,\n 'eval_precision': 0.8457775189283634,\n 'eval_recall': 0.8617374792309518,\n 'eval_f1': 0.853682911057551,\n 'eval_accuracy': 0.9714484035168903,\n 'eval_runtime': 9.1346,\n 'eval_samples_per_second': 378.012,\n 'eval_steps_per_second': 2.956,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"model.save_pretrained(\"lora_ner_model\")\ntokenizer.save_pretrained(\"lora_ner_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:16:32.689212Z","iopub.execute_input":"2024-12-22T16:16:32.689856Z","iopub.status.idle":"2024-12-22T16:16:32.819457Z","shell.execute_reply.started":"2024-12-22T16:16:32.689823Z","shell.execute_reply":"2024-12-22T16:16:32.818582Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"('lora_ner_model/tokenizer_config.json',\n 'lora_ner_model/special_tokens_map.json',\n 'lora_ner_model/vocab.txt',\n 'lora_ner_model/added_tokens.json',\n 'lora_ner_model/tokenizer.json')"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(ner_classes)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(ner_classes)\n}\n\nconfig = json.load(open(\"/kaggle/working/lora_ner_model/adapter_config.json\"))\nconfig[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id\njson.dump(config, open(\"/kaggle/working/lora_ner_model/adapter_config.json\",\"w\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:18:14.224185Z","iopub.execute_input":"2024-12-22T16:18:14.224925Z","iopub.status.idle":"2024-12-22T16:18:14.230507Z","shell.execute_reply.started":"2024-12-22T16:18:14.224888Z","shell.execute_reply":"2024-12-22T16:18:14.229695Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"print_size_of_model(peft_model), trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T16:24:40.554013Z","iopub.execute_input":"2024-12-22T16:24:40.554408Z","iopub.status.idle":"2024-12-22T16:24:41.314401Z","shell.execute_reply.started":"2024-12-22T16:24:40.554372Z","shell.execute_reply":"2024-12-22T16:24:41.313181Z"}},"outputs":[{"name":"stdout","text":"Size (KB): 435913.143\n","output_type":"stream"}],"execution_count":44}]}