{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/skshmjn/bert-ner?scriptVersionId=214644289\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install transformers datasets tokenizers seqeval evaluate peft -q \n!pip install -U accelerate \n!pip install bitsandbytes","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:39:56.280589Z","iopub.execute_input":"2024-12-24T19:39:56.280968Z","iopub.status.idle":"2024-12-24T19:40:05.060704Z","shell.execute_reply.started":"2024-12-24T19:39:56.280936Z","shell.execute_reply":"2024-12-24T19:40:05.05956Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting trl\n  Downloading trl-0.13.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from trl) (1.2.1)\nRequirement already satisfied: datasets>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from trl) (3.1.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\nRequirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.46.3)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.26.2)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.4.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.9.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.0->trl) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.0->trl) (0.20.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.34.0->trl) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2024.6.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\nDownloading trl-0.13.0-py3-none-any.whl (293 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: trl\nSuccessfully installed trl-0.13.0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import datasets \nimport numpy as np \nimport torch \nimport json\nfrom transformers import pipeline\nfrom evaluate import load\nfrom transformers import BertTokenizerFast\nfrom transformers import DataCollatorForTokenClassification , DataCollatorWithPadding\nfrom transformers import AutoModelForTokenClassification , AutoTokenizer\nfrom transformers import TrainingArguments, Trainer \nfrom transformers import  BitsAndBytesConfig\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:35:52.230403Z","iopub.execute_input":"2024-12-24T19:35:52.230757Z","iopub.status.idle":"2024-12-24T19:36:10.854875Z","shell.execute_reply.started":"2024-12-24T19:35:52.230723Z","shell.execute_reply":"2024-12-24T19:36:10.854017Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"conll2003 = datasets.load_dataset(\"conll2003\", trust_remote_code=True)\nconll2003","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:22.368074Z","iopub.execute_input":"2024-12-24T19:36:22.368424Z","iopub.status.idle":"2024-12-24T19:36:28.550524Z","shell.execute_reply.started":"2024-12-24T19:36:22.368392Z","shell.execute_reply":"2024-12-24T19:36:28.549749Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"541da2e7dbd148219b6fe283168c07ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dd7b014a5ca4620a093d0492083d4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b179039d6c70469eae011e374201be51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f10ee70718458bbb7b4ecce23a8dae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa194264276a4b9ba55444a2474104a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d676eb47d1c4ad690e4ea24a87a75ce"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"conll2003[\"train\"][0]","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ner_classes = conll2003[\"train\"].features[\"ner_tags\"].feature.names\nner_classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:28.551748Z","iopub.execute_input":"2024-12-24T19:36:28.55206Z","iopub.status.idle":"2024-12-24T19:36:28.55822Z","shell.execute_reply.started":"2024-12-24T19:36:28.552033Z","shell.execute_reply":"2024-12-24T19:36:28.557296Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"example = conll2003[\"train\"][345]\nexample['tokens'] ,[ner_classes[i] for i in example['ner_tags']]","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\ndef tokenize_and_align_labels(examples, label_all_tokens=True): \n\n    # Tokenisation\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True) \n    labels = [] \n\n    # checking all the labels and adding label for word piece \n    for i, label in enumerate(examples[\"ner_tags\"]):\n        \n        word_ids = tokenized_inputs.word_ids(batch_index=i) \n        previous_word_idx = None \n        label_ids = []\n        \n        for word_idx in word_ids: \n            if word_idx is None: \n               \n                label_ids.append(0)\n           \n            elif word_idx != previous_word_idx:\n               \n                label_ids.append(label[word_idx]) \n            else: \n               \n                label_ids.append(label[word_idx] if label_all_tokens else 0) \n                 \n            previous_word_idx = word_idx \n        labels.append(label_ids) \n    tokenized_inputs[\"labels\"] = labels \n    return tokenized_inputs ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:28.559367Z","iopub.execute_input":"2024-12-24T19:36:28.55962Z","iopub.status.idle":"2024-12-24T19:36:28.707996Z","shell.execute_reply.started":"2024-12-24T19:36:28.559596Z","shell.execute_reply":"2024-12-24T19:36:28.707196Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"result = tokenize_and_align_labels(conll2003['train'][345:346])\nprint(result)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(result[\"input_ids\"][0]),result[\"labels\"][0]): \n    print(f\"{token:_<40} {label}\") ","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns([\"tokens\",\"pos_tags\", \"chunk_tags\", \"ner_tags\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:31.639116Z","iopub.execute_input":"2024-12-24T19:36:31.639732Z","iopub.status.idle":"2024-12-24T19:36:33.607531Z","shell.execute_reply.started":"2024-12-24T19:36:31.639698Z","shell.execute_reply":"2024-12-24T19:36:33.606861Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a874de25777545b3b84ce444edd9a847"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b115affb0de64289874661cf10f49929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"956e4326d9ac46d8b15c63ffd920a3a9"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"tokenized_datasets['train'][0:3]","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer) \nmetric = load(\"seqeval\") \ndef compute_metrics(eval_preds): \n \n    pred_logits, labels = eval_preds \n    \n    pred_logits = np.argmax(pred_logits, axis=2) \n    \n    predictions = [ \n        [ner_classes[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n        for prediction, label in zip(pred_logits, labels) \n    ] \n    \n    true_labels = [ \n      [ner_classes[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n       for prediction, label in zip(pred_logits, labels) \n   ] \n    # print('true-->',true_labels[:4])\n    # print('predict-->',predictions[:4])\n\n    results = metric.compute(predictions=predictions, references=true_labels) \n    return { \n   \"precision\": results[\"overall_precision\"], \n   \"recall\": results[\"overall_recall\"], \n   \"f1\": results[\"overall_f1\"], \n  \"accuracy\": results[\"overall_accuracy\"], \n  } ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:53:25.215751Z","iopub.execute_input":"2024-12-24T19:53:25.216174Z","iopub.status.idle":"2024-12-24T19:53:25.696915Z","shell.execute_reply.started":"2024-12-24T19:53:25.21614Z","shell.execute_reply":"2024-12-24T19:53:25.696169Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"args = TrainingArguments( \n\"test-ner\",\nevaluation_strategy = \"epoch\", \nlearning_rate=2e-5, \nper_device_train_batch_size=64, \nper_device_eval_batch_size=64, \nnum_train_epochs=5, \nweight_decay=0.01, \n) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer( \n    model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"ner_model\")\ntokenizer.save_pretrained(\"tokenizer\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(ner_classes)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(ner_classes)\n}\n\nconfig = json.load(open(\"ner_model/config.json\"))\nconfig[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id\njson.dump(config, open(\"ner_model/config.json\",\"w\"))","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\").to(device)\nnlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)\n\nexample = \"Narendra Damodardas Modi[a] (born 17 September 1950)[b] is an Indian politician who has served as Prime Minister of India since 2014. Modi was the chief minister of Gujarat from 2001 to 2014 and is the member of parliament (MP) for Varanasi. He is a member of the Bharatiya Janata Party (BJP) and of the Rashtriya Swayamsevak Sangh (RSS), a right-wing Hindu nationalist paramilitary volunteer organisation. He is the longest-serving prime minister outside the Indian National Congress.\"\n\nner_results = nlp(example)\n\nprint(ner_results)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sudo apt-get install git-lfs","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quantisation","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade transformers auto-round","metadata":{"trusted":true,"scrolled":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"skshmjn/test-ner\").to(device)\nauto_round_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"skshmjn/test-ner\").to(device)\ntokenizer = AutoTokenizer.from_pretrained('skshmjn/test-ner')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from auto_round import AutoRound\nbits, group_size, sym = 4, 128, True\nautoround = AutoRound(auto_round_fine_tuned, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device=device)\nautoround.quantize()\nauto_round_fine_tuned.save_pretrained(\"auto_round_fine_tuned\")\n","metadata":{"trusted":true,"scrolled":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"auto_round_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"auto_round_fine_tuned\",torch_dtype=torch.float16)\nprint_size_of_model(auto_round_fine_tuned)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quantized_model = torch.quantization.quantize_dynamic(\n    model_fine_tuned, {torch.nn.Linear}, dtype=torch.qint8,\n).to('cpu')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_size_of_model(model):\n    torch.save(model.state_dict(), \"temp_delme.p\")\n    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n    os.remove('temp_delme.p')\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fine_tune_trainer = Trainer( \n    model_fine_tuned, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) \n\nquntised_trainer = Trainer( \n    quantized_model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics , \n) \n\nautoround_trainer = Trainer( \n    auto_round_fine_tuned, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(model_fine_tuned), fine_tune_trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(quantized_model), quntised_trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(auto_round_fine_tuned), autoround_trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(model_fine_tuned), print_size_of_model(quantized_model), print_size_of_model(auto_round_fine_tuned)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LORA\n","metadata":{}},{"cell_type":"markdown","source":"## using standard bert again to fine tune and compared result to earlier fine tuning","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, TaskType\nfrom peft import get_peft_model\n\nlora_config = LoraConfig(\n    task_type=TaskType.TOKEN_CLS, r=1, lora_alpha=1, lora_dropout=0.1\n)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\nmodel = AutoModelForTokenClassification.from_pretrained(\n    'bert-base-uncased', num_labels = 9\n)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"peft_model = get_peft_model(model, lora_config)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = TrainingArguments( \n\"lora-ner\",\nevaluation_strategy = \"epoch\", \nlearning_rate=1e-3, \nper_device_train_batch_size=64, \nper_device_eval_batch_size=64, \nnum_train_epochs=5, \nweight_decay=0.01\n) \ntrainer = Trainer( \n    model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n) ","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(\"lora_ner_model\")\ntokenizer.save_pretrained(\"lora_ner_model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(ner_classes)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(ner_classes)\n}\n\nconfig = json.load(open(\"/kaggle/working/lora_ner_model/adapter_config.json\"))\nconfig[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id\njson.dump(config, open(\"/kaggle/working/lora_ner_model/adapter_config.json\",\"w\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_size_of_model(peft_model), trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Qlora","metadata":{}},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:36:45.235856Z","iopub.execute_input":"2024-12-24T19:36:45.236564Z","iopub.status.idle":"2024-12-24T19:36:45.240589Z","shell.execute_reply.started":"2024-12-24T19:36:45.236529Z","shell.execute_reply":"2024-12-24T19:36:45.239615Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    num_labels=9, # For binary classification\n    quantization_config=bnb_config,\n    torch_dtype=torch.float32# Automatically place model on GPU/CPU\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:55:46.292836Z","iopub.execute_input":"2024-12-24T19:55:46.293675Z","iopub.status.idle":"2024-12-24T19:55:47.420485Z","shell.execute_reply.started":"2024-12-24T19:55:46.293638Z","shell.execute_reply":"2024-12-24T19:55:47.419831Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,  # Rank of the LoRA matrices\n    lora_alpha=8,  # Scaling factor\n    # target_modules=[\"query\", \"key\", \"value\"],  # Target attention modules\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\",  # Sequence classification task\n)\n\n# Add LoRA adapters to the model\nq_lora_model = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:55:47.421839Z","iopub.execute_input":"2024-12-24T19:55:47.422121Z","iopub.status.idle":"2024-12-24T19:55:47.458733Z","shell.execute_reply.started":"2024-12-24T19:55:47.422094Z","shell.execute_reply":"2024-12-24T19:55:47.457919Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"def print_size_of_model(model):\n    torch.save(model.state_dict(), \"temp_delme.p\")\n    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n    os.remove('temp_delme.p')\nprint_size_of_model(model), print_size_of_model(q_lora_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:55:48.509652Z","iopub.execute_input":"2024-12-24T19:55:48.510264Z","iopub.status.idle":"2024-12-24T19:55:49.165546Z","shell.execute_reply.started":"2024-12-24T19:55:48.510228Z","shell.execute_reply":"2024-12-24T19:55:49.164658Z"}},"outputs":[{"name":"stdout","text":"Size (KB): 141211.103\nSize (KB): 141229.535\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"args = TrainingArguments( \n\"qlora-ner\",\neval_strategy = \"epoch\", \nlearning_rate=1e-3, \nper_device_train_batch_size=64, \nper_device_eval_batch_size=64, \nnum_train_epochs=5, \nweight_decay=0.01,\nfp16=True,\nreport_to=\"none\"\n# optim = \"paged_adamw_32bit\"\n) \ntrainer = Trainer( \n    q_lora_model, \n    args, \n   train_dataset=tokenized_datasets[\"train\"], \n   eval_dataset=tokenized_datasets[\"validation\"], \n   data_collator=data_collator, \n   processing_class=tokenizer, \n   compute_metrics=compute_metrics \n) \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:57:23.842319Z","iopub.execute_input":"2024-12-24T19:57:23.842652Z","iopub.status.idle":"2024-12-24T19:57:23.876606Z","shell.execute_reply.started":"2024-12-24T19:57:23.842623Z","shell.execute_reply":"2024-12-24T19:57:23.875723Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T19:57:24.215214Z","iopub.execute_input":"2024-12-24T19:57:24.216146Z","iopub.status.idle":"2024-12-24T20:02:58.481625Z","shell.execute_reply.started":"2024-12-24T19:57:24.216096Z","shell.execute_reply":"2024-12-24T20:02:58.48091Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1100/1100 05:33, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.079036</td>\n      <td>0.866176</td>\n      <td>0.881195</td>\n      <td>0.873621</td>\n      <td>0.975521</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.062367</td>\n      <td>0.904661</td>\n      <td>0.911847</td>\n      <td>0.908240</td>\n      <td>0.981453</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.124300</td>\n      <td>0.057233</td>\n      <td>0.910213</td>\n      <td>0.924264</td>\n      <td>0.917185</td>\n      <td>0.982649</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.124300</td>\n      <td>0.056499</td>\n      <td>0.903637</td>\n      <td>0.928404</td>\n      <td>0.915853</td>\n      <td>0.982418</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.061500</td>\n      <td>0.054520</td>\n      <td>0.913363</td>\n      <td>0.930529</td>\n      <td>0.921866</td>\n      <td>0.983498</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1100, training_loss=0.08947390166195957, metrics={'train_runtime': 333.7378, 'train_samples_per_second': 210.36, 'train_steps_per_second': 3.296, 'total_flos': 2064573038563740.0, 'train_loss': 0.08947390166195957, 'epoch': 5.0})"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"trainer.evaluate(tokenized_datasets[\"test\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T20:02:58.482902Z","iopub.execute_input":"2024-12-24T20:02:58.483178Z","iopub.status.idle":"2024-12-24T20:03:06.495999Z","shell.execute_reply.started":"2024-12-24T20:02:58.483151Z","shell.execute_reply":"2024-12-24T20:03:06.495112Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [54/54 00:06]\n    </div>\n    "},"metadata":{}},{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.08911669999361038,\n 'eval_precision': 0.873308446103593,\n 'eval_recall': 0.8884405411820555,\n 'eval_f1': 0.8808095070008235,\n 'eval_accuracy': 0.9756594169366034,\n 'eval_runtime': 8.0047,\n 'eval_samples_per_second': 431.372,\n 'eval_steps_per_second': 6.746,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"q_lora_model.save_pretrained(\"qlora_ner_model\")\ntokenizer.save_pretrained(\"qlora_ner_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T20:07:30.450953Z","iopub.execute_input":"2024-12-24T20:07:30.451298Z","iopub.status.idle":"2024-12-24T20:07:30.749105Z","shell.execute_reply.started":"2024-12-24T20:07:30.451271Z","shell.execute_reply":"2024-12-24T20:07:30.748075Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"('qlora_ner_model/tokenizer_config.json',\n 'qlora_ner_model/special_tokens_map.json',\n 'qlora_ner_model/vocab.txt',\n 'qlora_ner_model/added_tokens.json',\n 'qlora_ner_model/tokenizer.json')"},"metadata":{}}],"execution_count":96},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(ner_classes)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(ner_classes)\n}\n\nconfig = json.load(open(\"/kaggle/working/qlora_ner_model/adapter_config.json\"))\nconfig[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id\njson.dump(config, open(\"/kaggle/working/qlora_ner_model/adapter_config.json\",\"w\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T20:08:16.800213Z","iopub.execute_input":"2024-12-24T20:08:16.800576Z","iopub.status.idle":"2024-12-24T20:08:16.808657Z","shell.execute_reply.started":"2024-12-24T20:08:16.800544Z","shell.execute_reply":"2024-12-24T20:08:16.807598Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T20:05:35.695901Z","iopub.execute_input":"2024-12-24T20:05:35.696227Z","iopub.status.idle":"2024-12-24T20:05:35.715109Z","shell.execute_reply.started":"2024-12-24T20:05:35.696201Z","shell.execute_reply":"2024-12-24T20:05:35.714276Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a911b7379cf498e8e7b61c8c1d0233f"}},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T20:08:45.297628Z","iopub.execute_input":"2024-12-24T20:08:45.297993Z","iopub.status.idle":"2024-12-24T20:08:50.454116Z","shell.execute_reply.started":"2024-12-24T20:08:45.297963Z","shell.execute_reply":"2024-12-24T20:08:50.453211Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735065257.c65e69f29fce.105.0:   0%|          | 0.00/5.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef84b2b5929845999a9563b5ebe00a09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 33 LFS files:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb1bbd0a23044e8ad23b710a46c8676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735064843.64bd9cde75e7.89.0:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a6216031c284fb0831a692cac7581e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735065743.aff3b00fc5e1.89.1:   0%|          | 0.00/6.82k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60cb78ba12b14420b0bc191ee700094b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.21M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaba1d009dd44fe59c0321340eff5e3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735065322.c65e69f29fce.105.1:   0%|          | 0.00/5.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"417bfb0144d3478eb5e843d9feeae3b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735066718.aff3b00fc5e1.89.2:   0%|          | 0.00/549 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce1836299ff6470c936f01ca1955d8a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067000.aff3b00fc5e1.89.3:   0%|          | 0.00/549 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500c112f6e9f4db5846bb577a9809161"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067043.aff3b00fc5e1.89.4:   0%|          | 0.00/12.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d9858a95e7c40d2ba513173115a1f05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067215.aff3b00fc5e1.89.5:   0%|          | 0.00/6.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b3ac975bb14691aab537c85ba28b92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067343.aff3b00fc5e1.89.6:   0%|          | 0.00/5.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02d9f38a33ec477c8ef36d3bc79e7427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067381.aff3b00fc5e1.89.7:   0%|          | 0.00/6.71k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01e29d40459744938573d6aa8430ec24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067533.aff3b00fc5e1.89.8:   0%|          | 0.00/6.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f409281a37194771af0260cd9b4984e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067655.aff3b00fc5e1.89.9:   0%|          | 0.00/6.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"345a86a92ee94e36912818f2c7fab2e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067693.aff3b00fc5e1.89.10:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c585e5aa39134aa7b716e9cf95fd65ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067729.aff3b00fc5e1.89.11:   0%|          | 0.00/549 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db50d92c98f6473581db0b83a49c1199"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735067770.aff3b00fc5e1.89.12:   0%|          | 0.00/6.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e217f1a8c3a4c0882c3c4357cc0059d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069020.e5da4b7b0f04.89.0:   0%|          | 0.00/5.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71021f142f7d4d8980c8e52d77cd76ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069228.e5da4b7b0f04.89.1:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c68eb9d0274289bec0ecca56795781"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069344.e5da4b7b0f04.89.2:   0%|          | 0.00/7.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7936e868a6245a58a4d8ead9bbdefef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069409.e5da4b7b0f04.89.3:   0%|          | 0.00/7.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29f294f89b424604af94fb0b54993347"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069609.e5da4b7b0f04.89.4:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0cbc859df114858b0d70aa2f2d8137a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069633.e5da4b7b0f04.89.5:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7143a4a585a149cca9b2281e0c2e5f91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069657.e5da4b7b0f04.89.7:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f54a0bf39754fb0863379d2d79654c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069650.e5da4b7b0f04.89.6:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"289ad41cc3494bb1b56900c234c459e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069673.e5da4b7b0f04.89.8:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16d1cf6c6df643518334eee8cb308435"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069690.e5da4b7b0f04.89.9:   0%|          | 0.00/6.68k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc0bffc4f974499e8ccb0b37bac1c84a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069738.e5da4b7b0f04.89.10:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3a90c045a684d4680d2b820370a0eea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069746.e5da4b7b0f04.89.11:   0%|          | 0.00/6.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9465406e1ec241858d29dc1cbde3e7cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069754.e5da4b7b0f04.89.12:   0%|          | 0.00/6.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8308bdc5578f4fcb9e58038e8779ff79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069845.e5da4b7b0f04.89.13:   0%|          | 0.00/7.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375313ac9c12400888040627f9ade533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069903.e5da4b7b0f04.89.14:   0%|          | 0.00/6.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8f241d831c843439baef3ab1042c123"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1735069969.e5da4b7b0f04.89.15:   0%|          | 0.00/6.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67a32ee6cbf4ac1a22f8371cb7da657"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f35a2f136984825a5d7748c5cde014a"}},"metadata":{}},{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/skshmjn/qlora-ner/commit/a0ba0c61df21245021686174b70e3beed54a254f', commit_message='End of training', commit_description='', oid='a0ba0c61df21245021686174b70e3beed54a254f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/skshmjn/qlora-ner', endpoint='https://huggingface.co', repo_type='model', repo_id='skshmjn/qlora-ner'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}